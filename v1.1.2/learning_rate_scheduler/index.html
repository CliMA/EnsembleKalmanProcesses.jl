<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Learning rate schedulers · EnsembleKalmanProcesses.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="EnsembleKalmanProcesses.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">EnsembleKalmanProcesses.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../installation_instructions/">Installation instructions</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../literated/sinusoid_example/">Simple example</a></li><li><a class="tocitem" href="../examples/Cloudy_example/">Cloudy</a></li><li><a class="tocitem" href="../examples/lorenz_example/">Lorenz</a></li><li><a class="tocitem" href="../literated/loss_minimization/">Minimization Loss</a></li><li><a class="tocitem" href="../literated/loss_minimization_sparse_eki/">Sparse Minimization Loss</a></li><li><a class="tocitem" href="../literated/aerosol_activation/">Aerosol activation</a></li><li><a class="tocitem" href="../examples/sinusoid_example_toml/">TOML interface</a></li><li><a class="tocitem" href="../examples/ClimateMachine_example/">HPC interfacing example: ClimateMachine</a></li><li><a class="tocitem" href="../examples/template_example/">Template</a></li></ul></li><li><a class="tocitem" href="../ensemble_kalman_inversion/">Ensemble Kalman Inversion</a></li><li><a class="tocitem" href="../ensemble_kalman_sampler/">Ensemble Kalman Sampler</a></li><li><a class="tocitem" href="../unscented_kalman_inversion/">Unscented Kalman Inversion</a></li><li class="is-active"><a class="tocitem" href>Learning rate schedulers</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Timestep-and-termination-time"><span>Timestep and termination time</span></a></li><li><a class="tocitem" href="#The-experiment-with-EKI-and-UKI"><span>The experiment with EKI &amp; UKI</span></a></li></ul></li><li><a class="tocitem" href="../parameter_distributions/">Prior distributions</a></li><li><a class="tocitem" href="../internal_data_representation/">Internal data representation</a></li><li><a class="tocitem" href="../localization/">Localization and SEC</a></li><li><a class="tocitem" href="../inflation/">Inflation</a></li><li><a class="tocitem" href="../parallel_hpc/">Parallelism and HPC</a></li><li><a class="tocitem" href="../observations/">Observations</a></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox"/><label class="tocitem" for="menuitem-14"><span class="docs-label">API</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../API/ParameterDistributions/">ParameterDistributions</a></li><li><a class="tocitem" href="../API/Observations/">Observations</a></li><li><a class="tocitem" href="../API/DataContainers/">DataContainers</a></li><li><a class="tocitem" href="../API/EnsembleKalmanProcess/">EnsembleKalmanProcess</a></li><li><a class="tocitem" href="../API/Inversion/">Inversion</a></li><li><a class="tocitem" href="../API/Unscented/">Unscented</a></li><li><a class="tocitem" href="../API/Sampler/">Sampler</a></li><li><a class="tocitem" href="../API/SparseInversion/">SparseInversion</a></li><li><a class="tocitem" href="../API/TOMLInterface/">TOML Interface</a></li><li><a class="tocitem" href="../API/Localizers/">Localizers</a></li></ul></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../glossary/">Glossary</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Learning rate schedulers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Learning rate schedulers</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/CliMA/EnsembleKalmanProcesses.jl/blob/main/docs/src/learning_rate_scheduler.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="learning-rate-schedulers"><a class="docs-heading-anchor" href="#learning-rate-schedulers">Learning Rate Schedulers (a.k.a) Timestepping</a><a id="learning-rate-schedulers-1"></a><a class="docs-heading-anchor-permalink" href="#learning-rate-schedulers" title="Permalink"></a></h1><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>We demonstrate the behaviour of different learning rate schedulers through solution of a nonlinear inverse problem.</p><p>In this example we have a model that produces the exponential of a sinusoid <span>$f(A, v) = \exp(A \sin(t) + v), \forall t \in [0,2\pi]$</span>. Given an initial guess of the parameters as <span>$A^* \sim \mathcal{N}(2,1)$</span> and <span>$v^* \sim \mathcal{N}(0,25)$</span>, the inverse problem is to estimate the parameters from a noisy observation of only the maximum and mean value of the true model output.</p><p>We shall compare the following configurations of implemented schedulers. </p><ol><li>Fixed, &quot;long&quot; timestep <code>DefaultScheduler(0.5)</code> - orange</li><li>Fixed, &quot;short&quot; timestep <code>DefaultScheduler(0.02)</code> - green</li><li>Adaptive timestep (designed originally to ensure EKS remains stable) <code>EKSStableScheduler()</code> <a href="https://doi.org/10.1088/1361-6420/ab1c3a">Kovachki &amp; Stuart 2018</a> - red</li><li>Misfit controlling timestep (Terminating) <code>DataMisfitController()</code> <a href="https://doi.org/10.1088/1361-6420/abd29b">Iglesias &amp; Yang 2021</a> - purple</li><li>Misfit controlling timestep (Continuing beyond Terminate condition) <code>DataMisfitController(on_terminate=&quot;continue&quot;)</code> - brown</li></ol><p>One can define the schedulers as</p><pre><code class="language-julia hljs">scheduler = DefaultScheduler(0.5) # fixed stepsize, default values: 1</code></pre><p>Then when constructing an EnsembleKalmanProcess, one uses the keyword argument</p><pre><code class="language-julia hljs">ekpobj = EKP.EnsembleKalmanProcess(args...; scheduler = scheduler, kwargs...)</code></pre><p>A variety of other schedulers can be defined similarly:</p><pre><code class="language-julia hljs">scheduler = MutableScheduler(2) # modifiable stepsize
scheduler = EKSStableScheduler(numerator=10.0, nugget = 0.01) # Stable for EKS
scheduler = DataMisfitController(on_terminate = &quot;continue&quot;) # non-terminating</code></pre><p>Please see the <a href="../API/EnsembleKalmanProcess/#scheduler_api">learning rate schedulers API</a> for defaults and other details</p><h3 id="Early-termination"><a class="docs-heading-anchor" href="#Early-termination">Early termination</a><a id="Early-termination-1"></a><a class="docs-heading-anchor-permalink" href="#Early-termination" title="Permalink"></a></h3><p>Early termination can be implemented in the calibration loop as </p><pre><code class="language-julia hljs">using EnsembleKalmanProcesses # for get_ϕ_final, update_ensemble!
# given
# * the number of iterations `N_iter`
# * a prior `prior`
# * a forward map `G`
# * the EKP object `ekpobj`

for i in 1:N_iter
    params_i = get_ϕ_final(prior, ekpobj)
    g_ens = G(params_i)
    terminated = update_ensemble!(ekpobj, g_ens) # check for termination
    if !isnothing(terminated) # if termination is flagged, break the loop
       break
    end
end </code></pre><h2 id="Timestep-and-termination-time"><a class="docs-heading-anchor" href="#Timestep-and-termination-time">Timestep and termination time</a><a id="Timestep-and-termination-time-1"></a><a class="docs-heading-anchor-permalink" href="#Timestep-and-termination-time" title="Permalink"></a></h2><p>Recall, for example for EKI, we perform updates of our ensemble of parameters <span>$j=1,\dots,J$</span> at step <span>$n = 1,\dots,N_\mathrm{it}$</span> using</p><p><span>$\theta_{n+1}^{(j)} = \theta_{n}^{(j)} - \dfrac{\Delta t_n}{J}\sum_{k=1}^J \left \langle \mathcal{G}(\theta_n^{(k)}) - \bar{\mathcal{G}}_n \, , \, \Gamma_y^{-1} \left ( \mathcal{G}(\theta_n^{(j)}) - y \right ) \right \rangle \theta_{n}^{(k)},$</span></p><p>where <span>$\bar{\mathcal{G}}_n$</span> is the mean value of <span>$\mathcal{G}(\theta_n)$</span> across ensemble members. We denote the current time <span>$t_n = \sum_{i=1}^n\Delta t_i$</span>, and the termination time as <span>$T = t_{N_\mathrm{it}}$</span>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Adaptive Schedulers typically try to make the biggest update that controls some measure of this update. For example, <code>EKSStableScheduler()</code> controls the frobenius norm of the update, while <code>DataMisfitController()</code> controls the Jeffrey divergence between the two steps. Largely they follow a pattern of scheduling very small initial timesteps, leading to much larger steps at later times.</p></div></div><p>There are two termination times that the theory indicates are useful</p><ul><li><span>$T=1$</span>: In the linear Gaussian case, the <span>$\{\theta_{N_\mathrm{it}}\}$</span> will represent the posterior distribution. In nonlinear case it should still provide an approximation to the posterior distribution. Note that as the posterior does not necessarily optimize the data-misfit we find <span>$\bar{\theta}_{N_\mathrm{it}}$</span> (the ensemble mean) provides a conservative estimate of the true parameters, while retaining spread. It is noted in <a href="https://doi.org/10.1088/1361-6420/abd29b">Iglesias &amp; Yang 2021</a> that with small enough (or well chosen) step-sizes this estimate at <span>$T=1$</span> satisfies a discrepancy principle with respect to the observational noise.</li><li><span>$T\to \infty$</span>: Though theoretical concerns have been made with respect to continuation beyond <span>$T=1$</span> for inversion methods such as EKI, in practice we commonly see better optimization of the data-misfit, and thus better representation <span>$\bar{\theta}_{N_\mathrm{it}}$</span> to the true parameters. As expected this procedure leads to ensemble collapse, and so no meaningful information can be taken from the posterior spread, and the optimizer is not likely to be the posterior mode.</li></ul><h2 id="The-experiment-with-EKI-and-UKI"><a class="docs-heading-anchor" href="#The-experiment-with-EKI-and-UKI">The experiment with EKI &amp; UKI</a><a id="The-experiment-with-EKI-and-UKI-1"></a><a class="docs-heading-anchor-permalink" href="#The-experiment-with-EKI-and-UKI" title="Permalink"></a></h2><p>We assess the schedulers by solving the inverse problem with EKI and UKI (we average results over 100 initial ensembles in the case of EKI). We will not draw comparisons between EKI and UKI here, rather we use them to observe consistent behavior in the schedulers. Shown below are the solution plots of one solve with each timestepper, for both methods. </p><p><img src="../assets/ensemble_compare_scheduler.png" alt="Solution EKI"/> <img src="../assets/ensemble_uki_compare_scheduler.png" alt="Solution UKI"/></p><p><em>Top: EKI, Bottom: UKI. Left: The true model over <span>$[0,2\pi]$</span> (black), and solution schedulers (colors). Right: The noisy observation (black) of mean and max of the model; the distribution it was sampled from (gray-ribbon), and the corresponding ensemble-mean approximation given from each scheduler (colors).</em></p><p>To assess the timestepping we show the convergence plot against the algorithm iteration we measure two quantities.</p><ul><li>error (solid) is defined by <span>$\frac{1}{N_{ens}}\sum^{N_{ens}}_{i=1} \| \theta_i - \theta^* \|^2$</span> where <span>$\theta_i$</span> are ensemble members and <span>$\theta^*$</span> is the true value used to create the observed data.</li><li>spread (dashed) is defined by <span>$\frac{1}{N_{ens}}\sum^{N_{ens}}_{i=1} \| \theta_i - \bar{\theta} \|^2$</span> where <span>$\theta_i$</span> are ensemble members and <span>$\bar{\theta}$</span> is the mean over these members.</li></ul><p><img src="../assets/error_vs_spread_over_iteration_compare_scheduler.png" alt="Error vs spread EKI"/> <img src="../assets/error_vs_spread_over_iteration_uki_compare_scheduler.png" alt="Error vs spread UKI"/></p><p><em>Top: EKI. Bottom: UKI. Left: the error and spread of the different timesteppers at over iterations of the algorithm for a single run. Right: the error and spread of the different timesteppers at their final iterations, (for EKI, averaged from 100 initial conditions).</em></p><p>Finding the Posterior (terminating at <span>$T=1$</span>):</p><ul><li>DMC with termination (purple), closely mimics a small-fixed timestep (green) that finishes stepping at <span>$T=1$</span>. Both retain more spread than other approaches, and DMC is far more efficient, typically terminating after around 10-20 steps, where fixed-stepping takes 50. We see that (for this experiment) this is a conservative estimate, as continuing to solve (e.g. brown) until later times often leads to a better error while still retaining similar &quot;error vs spread&quot; curves (before inevitable collapse). This is consistent with the concept of approximating the posterior, over seeking an optimizer.</li><li>The behavior observed in UKI is similar to EKI</li></ul><p>Optimizing the objective function (continuing <span>$T \to \infty$</span>):</p><ul><li>Large fixed step (orange). This is very efficient, but can get stuck when drawn too large, (perhaps unintuitive from a gradient-descent perspective). It typically also collapses the ensemble. On average it gives lower error to the true parameters than DMC. </li><li>Both EKSStable and DMC with continuation schedulers, perform very similarly. Both retain good ensemble spread during convergence, and collapse after finding a local optimum. This optimum on average has the best error to the true parameters in this experiment. They appear to consistently find the same optimum as <span>$T\to\infty$</span> but DMC finds this in fewer iterations.</li><li>The UKI behavior is largely similar to EKI here, except that ensemble spread is retained in the <span>$T\to\infty$</span> limit in all cases, from inflation of the parameter covariance (<span>$\Sigma_\omega$</span>) within our implementation. </li></ul><h3 id="DMC-as-a-default-in-future?"><a class="docs-heading-anchor" href="#DMC-as-a-default-in-future?">DMC as a default in future?</a><a id="DMC-as-a-default-in-future?-1"></a><a class="docs-heading-anchor-permalink" href="#DMC-as-a-default-in-future?" title="Permalink"></a></h3><p>This experiment motivates the possibility of making DMC (with/without) continuation a default timestepper in future releases, for EKI/SEKI/UKI. Currently we will retain constant timestepping as default while we investigate further.</p><div class="admonition is-warning"><header class="admonition-header">Ensemble Kalman Sampler</header><div class="admonition-body"><p>We observe blow-up in EKS, when not using the <code>EKSStableScheduler</code>.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../unscented_kalman_inversion/">« Unscented Kalman Inversion</a><a class="docs-footer-nextpage" href="../parameter_distributions/">Prior distributions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Thursday 27 July 2023 21:36">Thursday 27 July 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
