<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Unscented Kalman Inversion · EnsembleKalmanProcesses.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="EnsembleKalmanProcesses.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">EnsembleKalmanProcesses.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../installation_instructions/">Installation instructions</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../literated/sinusoid_example/">Simple example</a></li><li><a class="tocitem" href="../examples/Cloudy_example/">Cloudy</a></li><li><a class="tocitem" href="../examples/lorenz_example/">Lorenz</a></li><li><a class="tocitem" href="../literated/loss_minimization/">Minimization Loss</a></li><li><a class="tocitem" href="../literated/loss_minimization_sparse_eki/">Sparse Minimization Loss</a></li><li><a class="tocitem" href="../literated/aerosol_activation/">Aerosol activation</a></li><li><a class="tocitem" href="../examples/sinusoid_example_toml/">TOML interface</a></li><li><a class="tocitem" href="../examples/ClimateMachine_example/">HPC interfacing example: ClimateMachine</a></li><li><a class="tocitem" href="../examples/template_example/">Template</a></li></ul></li><li><a class="tocitem" href="../ensemble_kalman_inversion/">Ensemble Kalman Inversion</a></li><li><a class="tocitem" href="../ensemble_kalman_sampler/">Ensemble Kalman Sampler</a></li><li class="is-active"><a class="tocitem" href>Unscented Kalman Inversion</a><ul class="internal"><li><a class="tocitem" href="#Algorithm"><span>Algorithm</span></a></li><li><a class="tocitem" href="#Choice-of-free-parameters"><span>Choice of free parameters</span></a></li><li><a class="tocitem" href="#Implementation"><span>Implementation</span></a></li><li><a class="tocitem" href="#Solution"><span>Solution</span></a></li><li><a class="tocitem" href="#Handling-forward-model-failures"><span>Handling forward model failures</span></a></li></ul></li><li><a class="tocitem" href="../parameter_distributions/">Prior distributions</a></li><li><a class="tocitem" href="../internal_data_representation/">Internal data representation</a></li><li><a class="tocitem" href="../localization/">Localization and SEC</a></li><li><a class="tocitem" href="../inflation/">Inflation</a></li><li><a class="tocitem" href="../parallel_hpc/">Parallelism and HPC</a></li><li><a class="tocitem" href="../observations/">Observations</a></li><li><input class="collapse-toggle" id="menuitem-13" type="checkbox"/><label class="tocitem" for="menuitem-13"><span class="docs-label">API</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../API/ParameterDistributions/">ParameterDistributions</a></li><li><a class="tocitem" href="../API/Observations/">Observations</a></li><li><a class="tocitem" href="../API/DataContainers/">DataContainers</a></li><li><a class="tocitem" href="../API/EnsembleKalmanProcess/">EnsembleKalmanProcess</a></li><li><a class="tocitem" href="../API/Inversion/">Inversion</a></li><li><a class="tocitem" href="../API/Unscented/">Unscented</a></li><li><a class="tocitem" href="../API/Sampler/">Sampler</a></li><li><a class="tocitem" href="../API/SparseInversion/">SparseInversion</a></li><li><a class="tocitem" href="../API/TOMLInterface/">TOML Interface</a></li><li><a class="tocitem" href="../API/Localizers/">Localizers</a></li></ul></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../glossary/">Glossary</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Unscented Kalman Inversion</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Unscented Kalman Inversion</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/CliMA/EnsembleKalmanProcesses.jl/blob/main/docs/src/unscented_kalman_inversion.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Unscented-Kalman-Inversion"><a class="docs-heading-anchor" href="#Unscented-Kalman-Inversion">Unscented Kalman Inversion</a><a id="Unscented-Kalman-Inversion-1"></a><a class="docs-heading-anchor-permalink" href="#Unscented-Kalman-Inversion" title="Permalink"></a></h1><p>One of the ensemble Kalman processes implemented in <code>EnsembleKalmanProcesses.jl</code> is the unscented Kalman inversion (<a href="https://doi.org/10.1016/j.jcp.2022.111262">Huang, Schneider, Stuart, 2022</a>). The unscented Kalman inversion (UKI) is a derivative-free method for approximate Bayesian inference. We seek to find the posterior parameter distribution <span>$\theta \in \mathbb{R}^p$</span> from the inverse problem</p><p class="math-container">\[ y = \mathcal{G}(\theta) + \eta\]</p><p>where <span>$\mathcal{G}$</span> denotes the forward map, <span>$y \in \mathbb{R}^d$</span> is the vector of observations and <span>$\eta \sim \mathcal{N}(0, \Gamma_y)$</span> is additive Gaussian noise. Note that <span>$p$</span> is the size of the parameter vector <span>$\theta$</span> and <span>$d$</span> is taken to be the size of the observation vector <span>$y$</span>. The UKI algorithm has the following properties</p><ul><li>UKI has a fixed ensemble size, with members forming a quadrature stencil (rather than the random positioning of the particles from methods such as EKI). There are two quadrature options, <code>symmetric</code> (a <span>$2p + 1$</span>-size stencil), and <code>simplex</code> (a <span>$p+2$</span>-size stencil).</li><li>UKI has uncertainty quantification capabilities, it gives both mean and covariance approximation (no ensemble collapse and no empirical variance inflation) of the posterior distribution, the 3-sigma confidence interval covers the truth parameters for perfect models.</li></ul><h2 id="Algorithm"><a class="docs-heading-anchor" href="#Algorithm">Algorithm</a><a id="Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithm" title="Permalink"></a></h2><p>The UKI applies the unscented Kalman filter to the following stochastic dynamical system </p><p class="math-container">\[\begin{aligned}
  &amp;\textrm{evolution:}    &amp;&amp;\theta_{n+1} = r + \alpha (\theta_{n}  - r) +  \omega_{n+1}, &amp;&amp;\omega_{n+1} \sim \mathcal{N}(0,\Sigma_{\omega}),\\
  &amp;\textrm{observation:}  &amp;&amp;y_{n+1} = \mathcal{G}(\theta_{n+1}) + \nu_{n+1}, &amp;&amp;\nu_{n+1} \sim \mathcal{N}(0,\Sigma_{\nu}).
\end{aligned}\]</p><p>The free parameters in the UKI are <span>$\alpha, r, \Sigma_{\nu}, \Sigma_{\omega}$</span>. The UKI updates both the mean <span>$m_n$</span> and covariance <span>$C_n$</span> estimations of the parameter vector <span>$\theta$</span> as following</p><ul><li>Prediction step :</li></ul><p class="math-container">\[\begin{aligned}
    \hat{m}_{n+1} = &amp; r+\alpha(m_n-r)\\
    \hat{C}_{n+1} = &amp; \alpha^2 C_{n} + \Sigma_{\omega}
\end{aligned}\]</p><ul><li>Generate sigma points (&quot;the ensemble&quot;) :</li></ul><p>For the <code>sigma_points = symmetric</code> quadrature option, the ensemble is generated as follows.</p><p class="math-container">\[\begin{aligned}
    &amp;\hat{\theta}_{n+1}^0 = \hat{m}_{n+1} \\
    &amp;\hat{\theta}_{n+1}^j = \hat{m}_{n+1} + c_j [\sqrt{\hat{C}_{n+1}}]_j \quad (1\leq j\leq J)\\ 
    &amp;\hat{\theta}_{n+1}^{j+J} = \hat{m}_{n+1} - c_j [\sqrt{\hat{C}_{n+1}}]_j\quad (1\leq j\leq J)
\end{aligned}\]</p><p>where <span>$[\sqrt{C}]_j$</span> is the <span>$j$</span>-th column of the Cholesky factor of <span>$C$</span>. </p><ul><li>Analysis step :</li></ul><p class="math-container">\[   \begin{aligned}
        &amp;\hat{y}^j_{n+1} = \mathcal{G}(\hat{\theta}^j_{n+1}) \qquad \hat{y}_{n+1} = \hat{y}^0_{n+1}\\
         &amp;\hat{C}^{\theta p}_{n+1} = \sum_{j=1}^{2J}W_j^{c}
        (\hat{\theta}^j_{n+1} - \hat{m}_{n+1} )(\hat{y}^j_{n+1} - \hat{y}_{n+1})^T \\
        &amp;\hat{C}^{pp}_{n+1} = \sum_{j=1}^{2J}W_j^{c}
        (\hat{y}^j_{n+1} - \hat{y}_{n+1} )(\hat{y}^j_{n+1} - \hat{y}_{n+1})^T + \Sigma_{\nu}\\
        &amp;m_{n+1} = \hat{m}_{n+1} + \hat{C}^{\theta p}_{n+1}(\hat{C}^{pp}_{n+1})^{-1}(y - \hat{y}_{n+1})\\
        &amp;C_{n+1} = \hat{C}_{n+1} - \hat{C}^{\theta p}_{n+1}(\hat{C}^{pp}_{n+1})^{-1}{\hat{C}^{\theta p}_{n+1}}{}^{T}\\
    \end{aligned}\]</p><p>Where the coefficients <span>$c_j, W^c_j$</span> are given by</p><p class="math-container">\[    \begin{aligned}
    &amp;c_j = a\sqrt{J}, \qquad W_j^{c} = \frac{1}{2a^2J}~(j=1,\cdots,2N_{\theta}), \qquad  a=\min\{\sqrt{\frac{4}{J}},  1\} 
    \end{aligned}\]</p><h2 id="Choice-of-free-parameters"><a class="docs-heading-anchor" href="#Choice-of-free-parameters">Choice of free parameters</a><a id="Choice-of-free-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Choice-of-free-parameters" title="Permalink"></a></h2><p>The free parameters in the unscented Kalman inversion are <span>$\alpha, r, \Sigma_{\nu}, \Sigma_{\omega}$</span>, which are chosen based on theorems developed in <a href="https://doi.org/10.1016/j.jcp.2022.111262">Huang et al, 2021</a></p><ul><li><p>the vector <span>$r$</span> is set to be the prior mean</p></li><li><p>the scalar <span>$\alpha \in (0,1]$</span> is a regularization parameter, which is used to overcome ill-posedness and overfitting. A practical guide is </p><ul><li>When the observation noise is negligible, and there are more observations than parameters (identifiable inverse problem) <span>$\alpha = 1$</span> (no regularization)</li><li>Otherwise <span>$\alpha &lt; 1$</span>. The smaller <span>$\alpha$</span> is, the closer the UKI mean will converge to the prior mean.</li></ul></li><li><p>the matrix <span>$\Sigma_{\nu}$</span> is the artificial observation error covariance. We set <span>$\Sigma_{\nu} = 2 \Gamma_{y}$</span>, which makes the inverse problem consistent. </p></li><li><p>the matrix <span>$\Sigma_{\omega}$</span> is the artificial evolution error covariance. We set <span>$\Sigma_{\omega} = (2 - \alpha^2)\Lambda$</span>. We choose <span>$\Lambda$</span> as following</p><ul><li>when there are more observations than parameters (identifiable inverse problem), <span>$\Lambda = C_n$</span>, which is updated as the estimated covariance <span>$C_n$</span> in the <span>$n$</span>-th every iteration. This guarantees the converged covariance matrix is a good approximation to the posterior covariance matrix with an uninformative prior.</li></ul><ul><li>otherwise <span>$\Lambda = C_0$</span>, this allows that the converged covariance matrix is a weighted average between the posterior covariance matrix with an uninformative prior and <span>$C_0$</span>.</li></ul></li></ul><p>In short, users only need to change the <span>$\alpha$</span> (<code>α_reg</code>), and the frequency to update the <span>$\Lambda$</span> (<code>update_freq</code>). The user can first try <code>α_reg = 1.0</code> and <code>update_freq = 0</code>.</p><h2 id="Implementation"><a class="docs-heading-anchor" href="#Implementation">Implementation</a><a id="Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation" title="Permalink"></a></h2><h3 id="Initialization"><a class="docs-heading-anchor" href="#Initialization">Initialization</a><a id="Initialization-1"></a><a class="docs-heading-anchor-permalink" href="#Initialization" title="Permalink"></a></h3><p>An unscented Kalman inversion object can be created using the <code>EnsembleKalmanProcess</code> constructor by specifying the <code>Unscented()</code> process type.</p><p>Creating an ensemble Kalman inversion object requires as arguments:</p><ol><li>The mean value of the observed outputs, a vector of size <code>[d]</code>;</li><li>The covariance of the observational noise, a matrix of size <code>[d × d]</code>;</li><li>The <code>Unscented()</code> process type.</li></ol><p>The initialization of the <code>Unscented()</code> process requires prior mean and prior covariance, and the the size of the observation <code>d</code>. And user defined hyperparameters  <code>α_reg</code> and <code>update_freq</code>.</p><pre><code class="language-julia hljs">using EnsembleKalmanProcesses
using EnsembleKalmanProcesses.ParameterDistributions


# need to choose regularization factor α ∈ (0,1],  
# when you have enough observation data α=1: no regularization
α_reg =  1.0
# update_freq 1 : approximate posterior covariance matrix with an uninformative prior
#             0 : weighted average between posterior covariance matrix with an uninformative prior and prior
update_freq = 0

process = Unscented(prior_mean, prior_cov; α_reg = α_reg, update_freq = update_freq)
ukiobj = EnsembleKalmanProcess(truth_sample, truth.obs_noise_cov, process)
</code></pre><p>Note that no information about the forward map is necessary to initialize the Unscented process. The only forward map information required by the inversion process consists of model evaluations at the ensemble elements, necessary to update the ensemble.</p><h3 id="Constructing-the-Forward-Map"><a class="docs-heading-anchor" href="#Constructing-the-Forward-Map">Constructing the Forward Map</a><a id="Constructing-the-Forward-Map-1"></a><a class="docs-heading-anchor-permalink" href="#Constructing-the-Forward-Map" title="Permalink"></a></h3><p>At the core of the forward map <span>$\mathcal{G}$</span> is the dynamical model <span>$\Psi:\mathbb{R}^p \rightarrow \mathbb{R}^o$</span> (running <span>$\Psi$</span> is usually where the computational heavy-lifting is done), but the map <span>$\mathcal{G}$</span> may include additional components such as a transformation of the (unbounded) parameters <span>$\theta$</span> to a constrained domain the dynamical model can work with, or some post-processing of the output of <span>$\Psi$</span> to generate the observations. For example, <span>$\mathcal{G}$</span> may take the following form:</p><p class="math-container">\[\mathcal{G} = \mathcal{H} \circ \Psi \circ \mathcal{T}^{-1},\]</p><p>where <span>$\mathcal{H}:\mathbb{R}^o \rightarrow \mathbb{R}^d$</span> is the observation map and <span>$\mathcal{T}$</span> is the transformation from the constrained to the unconstrained parameter space, such that <span>$\mathcal{T}(\phi)=\theta$</span>. A family of standard transformations and their inverses are available in the <code>ParameterDistributions</code> module.</p><h3 id="Updating-the-Ensemble"><a class="docs-heading-anchor" href="#Updating-the-Ensemble">Updating the Ensemble</a><a id="Updating-the-Ensemble-1"></a><a class="docs-heading-anchor-permalink" href="#Updating-the-Ensemble" title="Permalink"></a></h3><p>Once the unscented Kalman inversion object <code>UKIobj</code> has been initialized, any number of updates can be performed using the inversion algorithm.</p><p>A call to the inversion algorithm can be performed with the <code>update_ensemble!</code> function. This function takes as arguments the <code>UKIobj</code> and the evaluations of the forward map at each element of the current ensemble. The <code>update_ensemble!</code> function then stores the new updated ensemble and the inputted forward map evaluations in <code>UKIobj</code>.</p><p>The forward map <span>$\mathcal{G}$</span> maps the space of unconstrained parameters <span>$\theta$</span> to the outputs <span>$y \in \mathbb{R}^d$</span>. In practice, the user may not have access to such a map directly. And the map is a composition of several functions. The <code>update_ensemble!</code> uses only the evalutaions <code>g_ens</code> but not the forward map  </p><p>For implementational reasons, the <code>update_ensemble</code> is performed by computing analysis stage first, followed by a calculation of the next sigma ensemble. The first sigma ensemble is created in the initialization.</p><pre><code class="language-julia hljs"># Given:
# Ψ (some black box simulator)
# H (some observation of the simulator output)
# prior (prior distribution and parameter constraints)

N_iter = 20 # Number of steps of the algorithm
 
for n in 1:N_iter
    ϕ_n = get_ϕ_final(prior, ukiobj) # Get current ensemble in constrained &quot;ϕ&quot;-space
    G_n = [H(Ψ(ϕ_n[:, i])) for i in 1:J]  # Evaluate forward map
    g_ens = hcat(G_n...)  # Reformat into `d x N_ens` matrix
    EnsembleKalmanProcesses.update_ensemble!(ukiobj, g_ens) # Update ensemble
end</code></pre><h2 id="Solution"><a class="docs-heading-anchor" href="#Solution">Solution</a><a id="Solution-1"></a><a class="docs-heading-anchor-permalink" href="#Solution" title="Permalink"></a></h2><p>The solution of the unscented Kalman inversion algorithm is a Gaussian distribution whose mean and covariance can be extracted from the &#39;&#39;last ensemble&#39;&#39; (i.e., the ensemble after the last iteration). The sample mean of the last ensemble is also the &quot;optimal&quot; parameter (<code>θ_optim</code>) for the given calibration problem. These statistics can be accessed as follows: </p><pre><code class="language-julia hljs"># mean of the Gaussian distribution, also the optimal parameter for the calibration problem
θ_optim = get_u_mean_final(ukiobj)
# covariance of the Gaussian distribution
sigma_optim = get_u_cov_final(ukiobj)</code></pre><p>There are two examples: <a href="../examples/lorenz_example/#Lorenz-example">Lorenz96</a> and <a href="../examples/Cloudy_example/#Cloudy-example">Cloudy</a>.</p><h2 id="Handling-forward-model-failures"><a class="docs-heading-anchor" href="#Handling-forward-model-failures">Handling forward model failures</a><a id="Handling-forward-model-failures-1"></a><a class="docs-heading-anchor-permalink" href="#Handling-forward-model-failures" title="Permalink"></a></h2><p>In situations where the forward model <span>$\mathcal{G}$</span> represents a diagnostic of a complex computational model, there might be cases where for some parameter combinations <span>$\theta$</span>, attempting to evaluate <span>$\mathcal{G}(\theta)$</span> may result in model failure (defined as returning a <code>NaN</code> from the point of view of this package). In such cases, the UKI update equations must be modified to handle model failures.</p><p><code>EnsembleKalmanProcesses.jl</code> implements such modifications through the <code>FailureHandler</code> structure, an input to the <code>EnsembleKalmanProcess</code> constructor. Currently, the only failsafe modification available is <code>SampleSuccGauss()</code>, described in <a href="https://doi.org/10.1029/2022MS003105">Lopez-Gomez et al (2022)</a>.</p><p>To employ this modification, construct the EKI object as</p><pre><code class="language-julia hljs">using EnsembleKalmanProcesses
using EnsembleKalmanProcesses.ParameterDistributions


# need to choose regularization factor α ∈ (0,1],  
# when you have enough observation data α=1: no regularization
α_reg =  1.0
# update_freq 1 : approximate posterior covariance matrix with an uninformative prior
#             0 : weighted average between posterior covariance matrix with an uninformative prior and prior
update_freq = 0

process = Unscented(prior_mean, prior_cov; α_reg = α_reg, update_freq = update_freq)
ukiobj = EnsembleKalmanProcess(
    truth_sample,
    truth.obs_noise_cov,
    process,
    failure_handler_method = SampleSuccGauss())
</code></pre><div class="admonition is-info"><header class="admonition-header">Forward model requirements when using FailureHandlers</header><div class="admonition-body"><p>The user must determine if a model run has &quot;failed&quot;, and replace the output <span>$\mathcal{G}(\theta)$</span> with <code>NaN</code>. The <code>FailureHandler</code> takes care of the rest.</p></div></div><p>A description of the algorithmic modification is included below.</p><h3 id="SampleSuccGauss-modification"><a class="docs-heading-anchor" href="#SampleSuccGauss-modification">SampleSuccGauss modification</a><a id="SampleSuccGauss-modification-1"></a><a class="docs-heading-anchor-permalink" href="#SampleSuccGauss-modification" title="Permalink"></a></h3><p>The <code>SampleSuccGauss()</code> modification is based on performing the UKI quadratures over the successful sigma points. Consider the set of off-center sigma points <span>$\{\hat{\theta}\} = \{\hat{\theta}_s\} \cup \{\hat{\theta}_f\}$</span> where <span>$\hat{\theta}_{s}^{(j)}$</span>,  <span>$j=1, \dots, J_s$</span> are successful members and <span>$\hat{\theta}_{f}^{(k)}$</span> are not. For ease of notation, consider an ordering of <span>$\{\hat{\theta}\}$</span> such that <span>$\{\hat{\theta}_s\}$</span> are its first <span>$J_s$</span> elements, and note that we deal with the central point <span>$\hat{\theta}^{(0)}$</span> separately. We estimate the covariances <span>$\mathrm{Cov}_q(\mathcal{G}_n, \mathcal{G}_n)$</span> and <span>$\mathrm{Cov}_q(\theta_{n}, \mathcal{G}_n)$</span> from the successful ensemble,</p><p class="math-container">\[   \tag{1} \mathrm{Cov}_q(\theta_n, \mathcal{G}_n) \approx \sum_{j=1}^{J_s}w_{s,j} (\hat{\theta}_{s, n}^{(j)} - \bar{\theta}_{s,n})(\mathcal{G}(\hat{\theta}_{s, n}^{(j)}) - \bar{\mathcal{G}}_{s,n})^T,\]</p><p class="math-container">\[   \tag{2} \mathrm{Cov}_q(\mathcal{G}_n, \mathcal{G}_n) \approx \sum_{j=1}^{J_s}w_{s,j} (\mathcal{G}(\hat{\theta}_{s, n}^{(j)}) - \bar{\mathcal{G}}_{s,n})(\mathcal{G}(\hat{\theta}_{s, n}^{(j)}) - \bar{\mathcal{G}}_{s,n})^T,\]</p><p>where the weights at each successful sigma point are scaled up, to preserve the sum of weights,</p><p class="math-container">\[    w_{s,j} = \left(\dfrac{\sum_{i=1}^{2p} w_i}{\sum_{k=1}^{J_s} w_k}\right)w_j.\]</p><p>In equations (1) and (2), the means <span>$\bar{\theta}_{s,n}$</span> and <span>$\bar{\mathcal{G}}_{s,n}$</span> must be modified from the original formulation if the central point <span>$\hat{\theta}^{(0)}=m_n$</span> results in model failure. If this is the case, then an average is taken across the other (successful) ensemble members</p><p class="math-container">\[   \bar{\theta}_{s,n} =
\dfrac{1}{J_s}\sum_{j=1}^{J_s}\hat{\theta}_{s, n}^{(j)}, \qquad   \bar{\mathcal{G}}_{s,n} =
\dfrac{1}{J_s}\sum_{j=1}^{J_s}\mathcal{G}(\hat{\theta}_{s, n}^{(j)}).\]</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ensemble_kalman_sampler/">« Ensemble Kalman Sampler</a><a class="docs-footer-nextpage" href="../parameter_distributions/">Prior distributions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Thursday 6 April 2023 21:11">Thursday 6 April 2023</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
