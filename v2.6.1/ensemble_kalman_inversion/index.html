<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Ensemble Kalman Inversion · EnsembleKalmanProcesses.jl</title><meta name="title" content="Ensemble Kalman Inversion · EnsembleKalmanProcesses.jl"/><meta property="og:title" content="Ensemble Kalman Inversion · EnsembleKalmanProcesses.jl"/><meta property="twitter:title" content="Ensemble Kalman Inversion · EnsembleKalmanProcesses.jl"/><meta name="description" content="Documentation for EnsembleKalmanProcesses.jl."/><meta property="og:description" content="Documentation for EnsembleKalmanProcesses.jl."/><meta property="twitter:description" content="Documentation for EnsembleKalmanProcesses.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="EnsembleKalmanProcesses.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">EnsembleKalmanProcesses.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../installation_instructions/">Installation instructions</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../literated/sinusoid_example/">Simple example</a></li><li><a class="tocitem" href="../literated/loss_minimization/">Minimization Loss</a></li><li><a class="tocitem" href="../examples/darcy/">Darcy flow</a></li><li><a class="tocitem" href="../examples/lorenz_example/">Lorenz</a></li><li><a class="tocitem" href="../examples/Cloudy_example/">Cloudy</a></li><li><a class="tocitem" href="../examples/sinusoid_example_toml/">TOML interface</a></li><li><a class="tocitem" href="../examples/ClimateMachine_example/">HPC interfacing example: ClimateMachine</a></li><li><a class="tocitem" href="../literated/loss_minimization_sparse_eki/">Sparse Minimization Loss</a></li></ul></li><li><a class="tocitem" href="../defaults/">List of default configurations</a></li><li class="is-active"><a class="tocitem" href>Ensemble Kalman Inversion</a><ul class="internal"><li><a class="tocitem" href="#What-we-optimize,-and-types-of-solution"><span>What we optimize, and types of solution</span></a></li><li><a class="tocitem" href="#The-EKI-update"><span>The EKI update</span></a></li><li><a class="tocitem" href="#Constructing-the-Forward-Map"><span>Constructing the Forward Map</span></a></li><li><a class="tocitem" href="#Creating-the-EKI-Object"><span>Creating the EKI Object</span></a></li><li><a class="tocitem" href="#Updating-the-Ensemble"><span>Updating the Ensemble</span></a></li><li><a class="tocitem" href="#Solution"><span>Solution</span></a></li><li class="toplevel"><a class="tocitem" href="#finite-vs-infinite-time"><span><code>Inversion()</code> vs <code>Inversion(prior)</code></span></a></li><li class="toplevel"><a class="tocitem" href="#etki"><span>Output-scalable variant: Ensemble Transform Kalman Inversion</span></a></li><li><a class="tocitem" href="#Using-ETKI"><span>Using ETKI</span></a></li><li class="toplevel"><a class="tocitem" href="#seki"><span>Sparsity-Inducing Ensemble Kalman Inversion</span></a></li></ul></li><li><a class="tocitem" href="../gauss_newton_kalman_inversion/">Gauss Newton Kalman Inversion</a></li><li><a class="tocitem" href="../ensemble_kalman_sampler/">Ensemble Kalman Sampler</a></li><li><a class="tocitem" href="../unscented_kalman_inversion/">Unscented Kalman Inversion</a></li><li><a class="tocitem" href="../learning_rate_scheduler/">Learning rate schedulers</a></li><li><a class="tocitem" href="../parameter_distributions/">Prior distributions</a></li><li><a class="tocitem" href="../observations/">Observations and Minibatching</a></li><li><a class="tocitem" href="../update_groups/">Update Groups</a></li><li><a class="tocitem" href="../localization/">Localization and SEC</a></li><li><a class="tocitem" href="../accelerators/">Accelerators</a></li><li><a class="tocitem" href="../inflation/">Inflation</a></li><li><a class="tocitem" href="../failure_handling/">Failure handling</a></li><li><a class="tocitem" href="../parallel_hpc/">Parallelism and HPC</a></li><li><a class="tocitem" href="../internal_data_representation/">Internal data representation</a></li><li><a class="tocitem" href="../visualization/">Visualization</a></li><li><a class="tocitem" href="../troubleshooting/">Troubleshooting</a></li><li><input class="collapse-toggle" id="menuitem-21" type="checkbox"/><label class="tocitem" for="menuitem-21"><span class="docs-label">API</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../API/ParameterDistributions/">ParameterDistributions</a></li><li><a class="tocitem" href="../API/Observations/">Observations</a></li><li><a class="tocitem" href="../API/DataContainers/">DataContainers</a></li><li><a class="tocitem" href="../API/EnsembleKalmanProcess/">EnsembleKalmanProcess</a></li><li><a class="tocitem" href="../API/Inversion/">Inversion</a></li><li><a class="tocitem" href="../API/Unscented/">Unscented</a></li><li><a class="tocitem" href="../API/Sampler/">Sampler</a></li><li><a class="tocitem" href="../API/SparseInversion/">SparseInversion</a></li><li><a class="tocitem" href="../API/TOMLInterface/">TOML Interface</a></li><li><a class="tocitem" href="../API/Localizers/">Localizers</a></li><li><a class="tocitem" href="../API/Visualize/">Visualize</a></li></ul></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../glossary/">Glossary</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Ensemble Kalman Inversion</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Ensemble Kalman Inversion</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/CliMA/EnsembleKalmanProcesses.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/CliMA/EnsembleKalmanProcesses.jl/blob/main/docs/src/ensemble_kalman_inversion.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><p>This page documents ensemble Kalman inversion (EKI), as well as two variants, <a href="#etki">ensemble transform Kalman inversion</a> (ETKI) and <a href="#seki">sparsity-inducing ensemble Kalman inversion</a> (SEKI).</p><h1 id="eki"><a class="docs-heading-anchor" href="#eki">Ensemble Kalman Inversion</a><a id="eki-1"></a><a class="docs-heading-anchor-permalink" href="#eki" title="Permalink"></a></h1><h2 id="What-we-optimize,-and-types-of-solution"><a class="docs-heading-anchor" href="#What-we-optimize,-and-types-of-solution">What we optimize, and types of solution</a><a id="What-we-optimize,-and-types-of-solution-1"></a><a class="docs-heading-anchor-permalink" href="#What-we-optimize,-and-types-of-solution" title="Permalink"></a></h2><p>One of the ensemble Kalman processes implemented in <code>EnsembleKalmanProcesses.jl</code> is ensemble Kalman inversion (<a href="http://dx.doi.org/10.1088/0266-5611/29/4/045001">Iglesias et al, 2013</a>). Ensemble Kalman inversion (EKI) is a derivative-free ensemble optimization method that seeks to find the optimal parameters <span>$\theta \in \mathbb{R}^p$</span> in the inverse problem defined by the data-model relation</p><p class="math-container">\[\tag{1} y = \mathcal{G}(\theta) + \eta ,\]</p><p>where <span>$\mathcal{G}$</span> denotes the forward map, <span>$y \in \mathbb{R}^d$</span> is the vector of observations and <span>$\eta  \in \mathbb{R}^d$</span> is additive noise. Note that <span>$p$</span> is the size of the parameter vector <span>$\theta$</span> and <span>$d$</span> the size of the observation vector <span>$y$</span>. Here, we take <span>$\eta \sim \mathcal{N}(0, \Gamma_y)$</span> from a <span>$d$</span>-dimensional Gaussian with zero mean and covariance matrix <span>$\Gamma_y$</span>.  This noise structure aims to represent the correlations between observations.</p><p>The optimal parameters <span>$\theta^* \in \mathbb{R}^p$</span> (Maximum Likelihood Estimation) given relation (1) minimize the loss </p><p class="math-container">\[\mathcal{L}(\theta, y) = \frac{1}{2} \left(y - \mathcal{G}(\theta)\right)^{\top} \Gamma_y^{-1} \left(y - \mathcal{G}(\theta) \right),\]</p><p>which can be interpreted as the negative log-likelihood given a Gaussian likelihood.</p><ul><li>This is acheived using process <code>Inversion()</code> and stepping to algorithm time <span>$T=\infty$</span>. This form uses the prior like an initial condition.</li></ul><p>If we using a prior to seek a Bayesian solution to our problem, (not just as initialization) then the optimal parameters <span>$\theta^* \in \mathbb{R}^p$</span> (Maximum A Posteriori estimation) given relation (1) minimize the loss </p><p class="math-container">\[\mathcal{L}(\theta, y) = \frac{1}{2} \left(y - \mathcal{G}(\theta)\right)^{\top} \Gamma_y^{-1} \left(y - \mathcal{G}(\theta) \right) + \frac{1}{2}(\theta - m)^{\top} C^{-1}(\theta-m)\]</p><p>which can be interpreted as the negative log-likelihood given a Gaussian likelihood and Gaussian prior <span>$N(m,C)$</span>. This is acheived in two ways:</p><ul><li>using process <code>Inversion()</code> and terminating the iterations at algorithm time <span>$T=1$</span> (default), &quot;finite-time variant&quot;</li><li>using process <code>Inversion(prior)</code> and stepping to <span>$T=\infty$</span>.  &quot;infinite-time variant&quot;</li></ul><p>See how these behave <a href="#finite-vs-infinite-time">here</a></p><h2 id="The-EKI-update"><a class="docs-heading-anchor" href="#The-EKI-update">The EKI update</a><a id="The-EKI-update-1"></a><a class="docs-heading-anchor-permalink" href="#The-EKI-update" title="Permalink"></a></h2><p>Denoting the parameter vector of the <span>$j$</span>-th ensemble member at the <span>$n$</span>-th iteration as <span>$\theta^{(j)}_n$</span>, its update equation from <span>$n$</span> to <span>$n+1$</span> under EKI is</p><p class="math-container">\[\tag{2} \theta_{j+1}^{(n)} = \theta_j^{(n)} + \Delta t C^{\theta\mathcal{G}}_j(\Gamma_y + \Delta t C_j^{\mathcal{GG}})^{-1}(y - \mathcal{G}(\theta_j^{(n)})).\]</p><p>Where the notations for means and covariances are given as</p><p class="math-container">\[\begin{aligned}
    C^{\theta\mathcal{G}}_j &amp;= \frac{1}{N}\sum_{n=1}^N \left[ (\theta^{(n)}_j - \overline{\theta_j})\otimes(\mathcal{G}(\theta^{(n)}_j) - \overline{ \mathcal{G}(\theta)}_j) \right],\\
    C^{\mathcal{GG}}_j &amp;= \frac{1}{N}\sum_{n=1}^N \left[(\mathcal{G}(\theta^{(n)}_j) - \overline{ \mathcal{G}(\theta)}_j)\otimes(\mathcal{G}(\theta^{(n)}_j) - \overline{ \mathcal{G}(\theta)}_j) \right],\\
    \overline{\theta}_j &amp;= \frac{1}{N}\sum_{n=1}^N \theta^{(n)}_j,\qquad \overline{\mathcal{G}(\theta)}_j = \frac{1}{N} \sum_{n=1}^N\mathcal{G}(\theta^{(n)}_j),\\
\end{aligned}\]</p><p>There is no difference between the <code>Inversion()</code> and <code>Inversion(prior)</code> updates, but the latter works with an augmented state (see <a href="#finite-vs-infinite-time">here</a>). The algorithmic timestep (a.k.a learning rate) <span>$\Delta t$</span> is usually taken to be adaptive with a schedule, as described <a href="../learning_rate_scheduler/#learning-rate-schedulers">here</a>.</p><p>The final estimate <span>$\bar{\theta}_{N_{\rm it}}$</span> is taken to be the ensemble mean at the final iteration, </p><p class="math-container">\[\bar{\theta}_{N_{\rm it}} = \dfrac{1}{J}\sum_{k=1}^J\theta_{N_{\rm it}}^{(k)}.\]</p><p>For typical applications, a near-optimal solution <span>$\theta$</span> can be found after as few as 10 iterations of the algorithm, or <span>$10\cdot J$</span> evaluations of the forward model <span>$\mathcal{G}$</span>. The rules of thumb of choosing <span>$J$</span> are see <a href="../defaults/#ens-size">here</a>, and to reduce errors when <span>$J \ll p$</span> , we have sampling-error-correction (localization) approaches <a href="../localization/#localization">here</a>. </p><h2 id="Constructing-the-Forward-Map"><a class="docs-heading-anchor" href="#Constructing-the-Forward-Map">Constructing the Forward Map</a><a id="Constructing-the-Forward-Map-1"></a><a class="docs-heading-anchor-permalink" href="#Constructing-the-Forward-Map" title="Permalink"></a></h2><p>The forward map <span>$\mathcal{G}$</span> maps the space of unconstrained parameters <span>$\theta \in \mathbb{R}^p$</span> to the space of outputs <span>$y \in \mathbb{R}^d$</span>. In practice, the user may not have access to such a map directly. Consider a situation where the goal is to learn a set of parameters <span>$\phi$</span> of a dynamical model <span>$\Psi: \mathbb{R}^p \rightarrow \mathbb{R}^o$</span>, given observations <span>$y \in \mathbb{R}^d$</span> and a set of constraints on the value of <span>$\phi$</span>. Then, the forward map may be constructed as</p><p class="math-container">\[\mathcal{G} = \mathcal{H} \circ \Psi \circ \mathcal{T}^{-1},\]</p><p>where <span>$\mathcal{H}: \mathbb{R}^o \rightarrow \mathbb{R}^d$</span> is the observation map and <span>$\mathcal{T}$</span> is the transformation map from constrained to unconstrained parameter spaces, such that <span>$\mathcal{T}(\phi) = \theta$</span>. A family of standard transformation maps and their inverse are available in the <code>ParameterDistributions</code> module.</p><h2 id="Creating-the-EKI-Object"><a class="docs-heading-anchor" href="#Creating-the-EKI-Object">Creating the EKI Object</a><a id="Creating-the-EKI-Object-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-the-EKI-Object" title="Permalink"></a></h2><p>An ensemble Kalman inversion object can be created using the <code>EnsembleKalmanProcess</code> constructor by specifying the <code>Inversion()</code> process type.</p><p>The <code>EnsembleKalmanProcess</code> then is built with and initial ensemble, observation and the process. The following utilities describe this</p><pre><code class="language-julia hljs">using EnsembleKalmanProcesses # for `construct_initial_ensemble`, `Inversion`, `Observation`
using EnsembleKalmanProcesses.ParameterDistributions # for `constrained_gaussian`

prior = constrained_gaussian(&quot;4d-unit-gauss&quot;, 0.0, 1.0, -Inf, Inf, repeats=4)

J = 50  # number of ensemble members
initial_ensemble = construct_initial_ensemble(prior, J) # Initialize ensemble from prior (unconstrained u-space)

# data
ydim = 5
y = ones(ydim)
cov_y = 0.01*I

# basic EKI, finite-time
ekiobj = EnsembleKalmanProcess(initial_ensemble, y, obs_noise_cov, Inversion())

# fancier observation container, infinite-time, verbose i/o
y_obs = Observation(
    Dict(
        &quot;samples&quot; =&gt; y,
        &quot;covariances&quot; =&gt; cov_y,
        &quot;names&quot; =&gt; &quot;descriptive_name&quot;,
        &quot;metadata&quot; =&gt; &quot;some imporant information&quot;
    ),
)

ekiobj = EnsembleKalmanProcess(initial_ensemble, y_obs, Inversion(prior), verbose=true)</code></pre><p>See the <a href="../parameter_distributions/#parameter-distributions">Prior distributions</a> section to learn about the construction of priors in EnsembleKalmanProcesses.jl. See the <a href="../observations/#observations">Observations</a> section to learn about more complex observation construction and minibatching utilities. Note that the initial ensemble is in the unconstrained <code>u</code> space, apply <code>transform_unconstrained_to_constrained(prior, initial_ensemble)</code> to see the resulting constrained parameter ensemble.</p><h2 id="Updating-the-Ensemble"><a class="docs-heading-anchor" href="#Updating-the-Ensemble">Updating the Ensemble</a><a id="Updating-the-Ensemble-1"></a><a class="docs-heading-anchor-permalink" href="#Updating-the-Ensemble" title="Permalink"></a></h2><p>Once the ensemble Kalman inversion object <code>ekiobj</code> has been initialized, any number of updates can be performed using the inversion algorithm.</p><p>A call to the inversion algorithm can be performed with the <code>update_ensemble!</code> function. This function takes as arguments the <code>ekiobj</code> and the evaluations of the forward map at each member of the current ensemble. The <code>update_ensemble!</code> function then stores the new updated ensemble and the inputted forward map evaluations in <code>ekiobj</code>. </p><p>A typical use of the <code>update_ensemble!</code> function given the ensemble Kalman inversion object <code>ekiobj</code>, the dynamical model <code>Ψ</code> and the observation map <code>H</code> is</p><pre><code class="language-julia hljs"># Given:
# Ψ (some black box simulator)
# H (some observation of the simulator output)
# prior (prior distribution and parameter constraints)

N_iter = 20 # Number of steps of the algorithm

for n in 1:N_iter
    ϕ_n = get_ϕ_final(prior, ekiobj) # Get current ensemble in constrained &quot;ϕ&quot;-space
    G_n = [H(Ψ(ϕ_n[:, i])) for i in 1:J]
    g_ens = hcat(G_n...) # Evaluate forward map 
    update_ensemble!(ekiobj, g_ens) # Update ensemble
end</code></pre><p>In the previous update, note that the parameters stored in <code>ekiobj</code> are given in the unconstrained Gaussian space where the EKI algorithm is performed. The map <span>$\mathcal{T}^{-1}$</span> between this unconstrained space and the (possibly constrained) physical space of parameters is encoded in the <code>prior</code> object. The dynamical model <code>Ψ</code> accepts as inputs the parameters in (possibly constrained) physical space, so it is necessary to use the getter <code>get_ϕ_final</code> which applies <code>transform_unconstrained_to_constrained</code> to the ensemble. See the <a href="../parameter_distributions/#parameter-distributions">Prior distributions</a> section for more details on parameter transformations.   </p><h2 id="Solution"><a class="docs-heading-anchor" href="#Solution">Solution</a><a id="Solution-1"></a><a class="docs-heading-anchor-permalink" href="#Solution" title="Permalink"></a></h2><p>The EKI algorithm drives the initial ensemble, sampled from the prior, towards the support region of the posterior distribution. The algorithm also drives the ensemble members towards consensus. The optimal parameter <code>θ_optim</code> found by the algorithm is given by the mean of the last ensemble (i.e., the ensemble after the last iteration),</p><pre><code class="language-julia hljs">θ_optim = get_u_mean_final(ekiobj) # optimal parameter</code></pre><p>To obtain the optimal value in the constrained space, we use the getter with the constrained prior as input</p><pre><code class="language-julia hljs">ϕ_optim = get_ϕ_mean_final(prior, ekiobj) # the optimal physical parameter value</code></pre><h1 id="finite-vs-infinite-time"><a class="docs-heading-anchor" href="#finite-vs-infinite-time"><code>Inversion()</code> vs <code>Inversion(prior)</code></a><a id="finite-vs-infinite-time-1"></a><a class="docs-heading-anchor-permalink" href="#finite-vs-infinite-time" title="Permalink"></a></h1><div class="admonition is-info" id="Finite-time-vs-infinite-time-f224747b53ba72a5"><header class="admonition-header">Finite-time vs infinite-time<a class="admonition-anchor" href="#Finite-time-vs-infinite-time-f224747b53ba72a5" title="Permalink"></a></header><div class="admonition-body"><p>Deeper description of these algorithms is discussed in detail in, for example, Section 4.5 of <a href="https://arxiv.org/pdf/2209.11371">Calvello, Reich, Stuart</a>). Finite-time algorithms have also been called &quot;transport&quot; algorithms, and infinite-time algorithms are also known as prior-enforcing, or Tikhonov EKI <a href="https://doi.org/10.1137/19M1242331">Chada, Stuart, Tong</a>.</p></div></div><p>Thus far, we have presented the finite-time algorithm <code>Inversion()</code>. The infinite-time variant <code>Inversion(prior)</code> algorithm has two key practical distinctions.</p><ol><li>The initial distribution does not need to come from the prior. </li><li>The particle distribution mean converges to the maximum a-posteriori estimator as <span>$T\to \infty$</span> (not via an <a href="../learning_rate_scheduler/#early-terminate">early-termination condition</a>)</li></ol><p>Both implementations perform the same update; but in the infinite-time variant, the forward-map, data and noise-covariance are augmented by a Gaussian prior <span>$N(m,C)$</span> by working with the following:</p><p class="math-container">\[\tilde{\mathcal{G}}(\theta) = [ \mathcal{G}(\theta), \theta] \qquad \tilde{y} = \left[ y, m \right]^{\top}, \qquad \tilde{\Gamma}_y = \begin{bmatrix} \Gamma_y &amp; 0 \\ 0 &amp; C \end{bmatrix}\]</p><p>It is implemented as follows (here, for three parameters)</p><pre><code class="language-julia hljs">using EnsembleKalmanProcesses
using EnsembleKalmanProcesses.ParameterDistributions
# given `y` `obs_noise_cov` and `prior`

J = 50  # number of ensemble members
initial_dist = constrained_gaussian(&quot;not-the-prior&quot;, 0, 1, -Inf, Inf, repeats=3)
initial_ensemble = construct_initial_ensemble(inital_dist, J) # Initialize ensemble from prior

ekiobj = EnsembleKalmanProcess(initial_ensemble, y, obs_noise_cov, Inversion(prior))</code></pre><p>One can see this in-action with the finite- vs infinite-time comparison example <a href="https://github.com/CliMA/EnsembleKalmanProcesses.jl/blob/main/examples/LossMinimization/">here</a>, which was used to produce the plots below:</p><p><strong>Left: <code>Inversion</code> (finite-time), Right: <code>Inversion(prior)</code> (infinite-time, initialized off-prior)</strong></p><img src="../assets/animations/animated_inversion-finite.gif" width="300"> <img src="../assets/animations/animated_inversion-infinite.gif" width="300"> <p>Comparative behaviour. </p><ol><li><strong>Initialization:</strong> <code>Inversion()</code> must be initialized from the prior, <code>Inversion(prior)</code> can still find the posterior when initialized off-prior. This might be useful when the prior is very broad and can enter, for example, regions of instability of the users forward model</li><li><strong>Prior information:</strong> <code>Inversion()</code> only contains prior information due to its initialization, <code>Inversion(prior)</code> enforces the prior at every iteration.</li><li><strong>Solution</strong>: <code>Inversion()</code> terminated at <span>$T=1$</span> (implemented by default) obtains an accurate MAP estimate, the ensemble spread at exactly <span>$T=1$</span> can represent a snapshot of the true (Gaussian-approximated) uncertainty. <code>Inversion(prior)</code> obtains this in the limit <span>$T\to\infty$</span>, and undergoes collapse providing no uncertainty information.</li><li><strong>Trust in prior</strong> <code>Inversion()</code>, when iterated beyond <span>$T=1$</span> will lose prior information and thus move to find the MLE (minimize the data-misfit only) at <span>$T\to\infty$</span>, this behaviour might be useful if the prior information is missprecified.  </li><li><strong>Efficiency</strong>: <code>Inversion()</code> is more efficient that <code>Inversion(prior)</code> as enforcing the prior in the infinite-time algorithm is performed via extending the linear systems to be solved. Performance is also impacted (positively or negatively) by the choice of initial distribution in the <code>Inversion(prior)</code></li></ol><p>One can learn more about the early termination for finite-time algorithms <a href="../learning_rate_scheduler/#early-terminate">here</a>.</p><h1 id="etki"><a class="docs-heading-anchor" href="#etki">Output-scalable variant: Ensemble Transform Kalman Inversion</a><a id="etki-1"></a><a class="docs-heading-anchor-permalink" href="#etki" title="Permalink"></a></h1><p>Ensemble transform Kalman inversion (ETKI) is a variant of EKI based on the ensemble transform Kalman filter (<a href="http://doi.org/10.1175/1520-0493(2001)129&lt;0420:ASWTET&gt;2.0.CO;2">Bishop et al., 2001</a>). It is a form of ensemble square-root inversion, and an implementation can be found in <a href="http://doi.org/10.1088/1361-6420/ac99fa">Huang et al., 2022</a>. The main advantage of ETKI over EKI is that it has better scalability as the observation dimension grows: while the naive implementation of EKI scales as <span>$\mathcal{O}(p^3)$</span> in the observation dimension <span>$p$</span>, ETKI scales as <span>$\mathcal{O}(p)$</span>. This, however, refers to the online cost. ETKI may have an offline cost of <span>$\mathcal{O}(p^3)$</span> if <span>$\Gamma$</span> is not easily invertible; see below.</p><p>The major disadvantage of ETKI is that it cannot be used with localization or sampling error correction. </p><div class="admonition is-info" id="Creating-scalable-observational-covariances-1d60a21f0a5ef46b"><header class="admonition-header">Creating scalable observational covariances<a class="admonition-anchor" href="#Creating-scalable-observational-covariances-1d60a21f0a5ef46b" title="Permalink"></a></header><div class="admonition-body"><p>ETKI requires storing and inverting the observation noise covariance, <span>$\Gamma^{-1}$</span>. Without care, this can be prohibitively expensive. To this end, we have tools and an API for creating and using scalable or compact representations of covariances that are necessary for scalability. See <a href="../observations/#building-covariances">here</a> for details and examples. </p></div></div><h2 id="Using-ETKI"><a class="docs-heading-anchor" href="#Using-ETKI">Using ETKI</a><a id="Using-ETKI-1"></a><a class="docs-heading-anchor-permalink" href="#Using-ETKI" title="Permalink"></a></h2><p>An ETKI struct can be created using the <code>EnsembleKalmanProcess</code> constructor by specifying the <code>TransformInversion</code> process type: </p><pre><code class="language-julia hljs">using EnsembleKalmanProcesses
# given the prior distribution `prior`, data `y` and covariance `obs_noise_cov`,

J = 50  # number of ensemble members
initial_ensemble = construct_initial_ensemble(prior, J) # Initialize ensemble from prior

etkiobj = EnsembleKalmanProcess(initial_ensemble, y, obs_noise_cov,
                               TransformInversion())</code></pre><p>The rest of the inversion process is the same as for regular EKI.</p><h1 id="seki"><a class="docs-heading-anchor" href="#seki">Sparsity-Inducing Ensemble Kalman Inversion</a><a id="seki-1"></a><a class="docs-heading-anchor-permalink" href="#seki" title="Permalink"></a></h1><p>We include Sparsity-inducing Ensemble Kalman Inversion (SEKI) to add approximate <span>$L^0$</span> and <span>$L^1$</span> penalization to the EKI (<a href="https://doi.org/10.48550/arXiv.2007.06175">Schneider, Stuart, Wu, 2020</a>).</p><div class="admonition is-warning" id="Warning-a745296964aeb0b9"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-a745296964aeb0b9" title="Permalink"></a></header><div class="admonition-body"><p>The algorithm suffers from robustness issues, and therefore we urge caution in using the tool</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../defaults/">« List of default configurations</a><a class="docs-footer-nextpage" href="../gauss_newton_kalman_inversion/">Gauss Newton Kalman Inversion »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Wednesday 21 January 2026 16:58">Wednesday 21 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
