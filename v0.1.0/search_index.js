var documenterSearchIndex = {"docs":
[{"location":"observations/#Observations","page":"Observations","title":"Observations","text":"","category":"section"},{"location":"observations/","page":"Observations","title":"Observations","text":"The Observations object is used to store the truth for convenience of the user. The ingredients are","category":"page"},{"location":"observations/","page":"Observations","title":"Observations","text":"Samples of the data Vector{Vector{Float}} or Array{Float,2}. If provided as a 2D array, the samples must be provided as columns. They are stored internally as Vector{Vector{Float}}\nAn optional covariance matrix can be provided.\nThe names of the data in this object as a String or Vector{String}","category":"page"},{"location":"observations/","page":"Observations","title":"Observations","text":"The empirical mean is calculated automatically. If a covariance matrix is not provided, then the empirical covariance is also calculated automatically.","category":"page"},{"location":"observations/#A-simple-example:","page":"Observations","title":"A simple example:","text":"","category":"section"},{"location":"observations/","page":"Observations","title":"Observations","text":"Here is a typical construction of the object","category":"page"},{"location":"observations/","page":"Observations","title":"Observations","text":"μ = zeros(5)\nΓy = rand(5,5)\nΓy = Γy'*Γy\nyt = rand(MvNormal(μ, Γy), 100) # generate 100 samples\nname = \"zero-mean mvnormal\"\n\ntrue_data = Observations.Obs(yt, Γy, name)","category":"page"},{"location":"observations/","page":"Observations","title":"Observations","text":"Currently, the data is retrieved by accessing the stored variables e.g the fifth data sample is given by truth_data.samples[5],or the covariance matrix by truth_data.cov.","category":"page"},{"location":"ensemble_kalman_sampler/#Ensemble-Kalman-Sampling","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampling","text":"","category":"section"},{"location":"ensemble_kalman_sampler/#What-Is-It-and-What-Does-It-Do?","page":"Ensemble Kalman Sampler","title":"What Is It and What Does It Do?","text":"","category":"section"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"Ensemble Kalman Sampling (Garbuno-Inigo et al, 2019, Cleary et al, 2020) is a derivative-free optimization method that can be used to solve the inverse problem of finding the optimal model parameters given noisy data. In contrast to ensemble Kalman inversion (Iglesias et al, 2013), whose iterative updates result in a collapse of the ensemble onto the optimal parameter, the ensemble Kalman sampler generates approximate samples from the Bayesian posterior distribution of the parameter – i.e., it can be used not only for point estimation of the optimal parameter (as provided by the mean of the particles after the last iteration), but also for (approximative) uncertainty quantification (as provided by the covariance of the particles after the last iteration). ","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The ensemble Kalman sampler is an interacting particle system in stochastic differential equation form, and it is based on a dynamic which transforms an arbitrary initial distribution into the desired posterior distribution, over an infinite time horizon – see Garbuno-Inigo et al, 2019, for a comprehensive description of the method. The ensemble Kalman sampling algorithm results from the introduction of a judiciously chosen noise to the ensemble Kalman inversion algorithm. Note that while there are also noisy variants of the standard ensemble Kalman inversion, ensemble Kalman sampling differs from them in its noise structure (its noise is added in parameter space, not in  data space), and its update rule explicitly accounts for the prior (rather than having it enter through initialization).","category":"page"},{"location":"ensemble_kalman_sampler/#Problem-Formulation","page":"Ensemble Kalman Sampler","title":"Problem Formulation","text":"","category":"section"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The data y and parameter vector theta are assumed to be related according to:","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"    y = mathcalG(theta) + eta","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"where mathcalG  mathbbR^p rightarrow mathbbR^d denotes the forward map, y in mathbbR^d is the vector of observations, and eta is the observational noise, which is assumed to be drawn from a d-dimensional Gaussian with distribution mathcalN(0 Gamma_y). The objective of the inverse problem is to compute the unknown parameters theta given the observations y, the known forward map mathcalG, and noise characteristics eta of the process. ","category":"page"},{"location":"ensemble_kalman_sampler/#Ensemble-Kalman-Sampling-Algorithm","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampling Algorithm","text":"","category":"section"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The ensemble Kalman sampler is based on the following update equation for the parameter vector theta^(j) of ensemble member j:","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"beginaligned\ntheta_n+1^(* j) = theta_n^(j) - dfracDelta t_nJsum_k=1^Jlangle mathcalG(theta_n^(k)) - barmathcalG_n Gamma_y^-1(mathcalG(theta_n^(j)) - y) rangle theta_n^(k) - Delta t_n mathsfC(Theta_n) Gamma_theta^-1 theta_n + 1^(* j) \ntheta_n + 1^j = theta_n+1^(* j) + sqrt2 Delta t_n mathsfC(Theta_n) xi_n^j\nendaligned","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"where the subscript n=1 dots N_it indicates the iteration, J is the ensemble size (i.e., the number of particles in the ensemble), Delta t_n is an adaptive time step, Gamma_theta is the prior covariance, and xi_n^(j) sim mathcalN(0 mathrmI). barmathcalG_n is the ensemble mean of mathcalG(theta),","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"barmathcalG_n = dfrac1Jsum_k=1^JmathcalG(theta_n^(k))","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The p times p matrix mathsfC(Theta_n), where Theta_n = lefttheta^(j)right_j=1^J is the set of all ensemble particles in the nth iteration, denotes the empirical covariance between particles,","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"mathsfC(Theta_n) = frac1J sum_k=1^J (theta^(k) - bartheta) otimes (theta^(k) - bartheta)","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"where bartheta is the ensemble mean of the particles,","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"bartheta = dfrac1Jsum_k=1^Jtheta^(k)","category":"page"},{"location":"ensemble_kalman_sampler/#Constructing-the-Forward-Map","page":"Ensemble Kalman Sampler","title":"Constructing the Forward Map","text":"","category":"section"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"At the core of the forward map mathcalG is the dynamical model PsimathbbR^p rightarrow mathbbR^o (running Psi is usually where the computational heavy-lifting is done), but the map mathcalG may include additional components such as a transformation of the (unbounded) parameters theta to a constrained domain the dynamical model can work with, or some post-processing of the output of Psi to generate the observations. For example, mathcalG may take the following form:","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"mathcalG = mathcalH circ Psi circ mathcalT^-1","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"where mathcalHmathbbR^o rightarrow mathbbR^d is the observation map and mathcalT is the transformation from the constrained to the unconstrained parameter space, such that mathcalT(phi)=theta. A family of standard transformations and their inverses are available in the ParameterDistributionStorage module.","category":"page"},{"location":"ensemble_kalman_sampler/#How-to-Construct-an-Ensemble-Kalman-Sampler","page":"Ensemble Kalman Sampler","title":"How to Construct an Ensemble Kalman Sampler","text":"","category":"section"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"An ensemble Kalman sampling object can be created using the EnsembleKalmanProcess constructor by specifying the Sampler(prior_mean, prior_cov) process type.","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"Creating an ensemble Kalman inversion object requires as arguments:","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"An initial parameter ensemble – an array of size p × N_ens, where N_ens is the  ensemble size;","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The mean value of the observed data – a vector of length d;","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The covariance matrix of the observational noise – an array of size d × d;","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The Sampler(prior_mean, prior_cov) process type, with the mean (a vector of length p) and the covariance (an array of size p x p) of the parameter's prior distribution","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The following example shows how an ensemble Kalman sampling object is instantiated. The mean of the observational data (obs_mean) and the covariance of the observational noise (obs_cov) are assumed to be defined previously in the code.","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"using EnsembleKalmanProcesses.EnsembleKalmanProcessModule\nusing EnsembleKalmanProcesses.ParameterDistributionStorage  # required to create the prior\n\n# Construct prior (see `ParameterDistributionStorage.jl` docs)\nprior = ParameterDistribution(...)\nprior_mean = get_mean(prior)\nprior_cov = get_cov(prior)\n\n# Construct initial ensemble\nN_ens = 50  # ensemble size\ninitial_ensemble = construct_initial_ensemble(prior, N_ens) \n\n# Construct ensemble Kalman process \neks_process = Sampler(prior_mean, prior_cov)\neks_obj = EnsembleKalmanProcess(initial_ensemble, obs_mean, obs_noise_cov, eks_process)","category":"page"},{"location":"ensemble_kalman_sampler/#Updating-the-ensemble","page":"Ensemble Kalman Sampler","title":"Updating the ensemble","text":"","category":"section"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"Once the ensemble Kalman sampling object eks_obj has been initialized, the initial ensemble of particles is iteratively updated by the update_ensemble! function, which takes as arguments the eks_obj and the evaluations of the forward model at each member of the current ensemble. In the following example, the forward map G maps a parameter to the corresponding data – this is done for each parameter in the ensemble, such that the resulting g_ens is of size d x N_ens. The update_ensemble! function then stores the updated ensemble as well as the evaluations of the forward map in eks_obj.","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"A typical use of the update_ensemble! function given the ensemble Kalman sampler object eks_obj, the dynamical model Ψ, and the observation map H (the latter two are assumed to be defined elsewhere, e.g. in a separate module)  may look as follows:","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"N_iter = 10 # Number of iterations\n\nfor n in 1:N_iter\n    θ_n = get_u_final(eks_obj) # Get current ensemble\n    ϕ_n = transform_unconstrained_to_constrained(prior, θ_n) # Transform parameters to physical/constrained space\n    G_n = [H(Ψ(ϕ_n[:, i])) for i in 1:J]  # Evaluate forward map\n    g_ens = hcat(G_n...)  # Reformat into `d x N_ens` matrix\n    update_ensemble!(eks_obj, g_ens) # Update ensemble\nend","category":"page"},{"location":"ensemble_kalman_sampler/#Solution","page":"Ensemble Kalman Sampler","title":"Solution","text":"","category":"section"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"The solution of the ensemble Kalman sampling algorithm is a Gaussian distribution whose mean and covariance can be extracted from the ''last ensemble'' (i.e., the ensemble after the last iteration). The sample mean of the last ensemble is also the \"optimal\" parameter (θ_optim) for the given calibration problem. These statistics can be accessed as follows: ","category":"page"},{"location":"ensemble_kalman_sampler/","page":"Ensemble Kalman Sampler","title":"Ensemble Kalman Sampler","text":"using Statistics\n\n# mean of the Gaussian distribution, also the optimal parameter for the calibration problem\nθ_optim = mean(get_u_final(eks_obj), dims=2)\n# covariance of the Gaussian distribution\nsigma = cov(get_u_final(eks_obj), dims=2)","category":"page"},{"location":"API/Observations/#Observations","page":"Observations","title":"Observations","text":"","category":"section"},{"location":"API/Observations/","page":"Observations","title":"Observations","text":"CurrentModule = EnsembleKalmanProcesses.Observations","category":"page"},{"location":"API/Observations/","page":"Observations","title":"Observations","text":"Obs","category":"page"},{"location":"API/Observations/#EnsembleKalmanProcesses.Observations.Obs","page":"Observations","title":"EnsembleKalmanProcesses.Observations.Obs","text":"Obs{FT<:AbstractFloat}\n\nStructure that contains the observations\n\nFields\n\nsamples\nvector of observational samples, each of length sample_dim\nobs_noise_cov\ncovariance of the observational noise (assumed to be normally     distributed); sampledim x sampledim (where sampledim is the number of     elements in each sample), or a scalar if the sample dim is 1. If not     supplied, obsnoisecov is set to a diagonal matrix whose non-zero elements     are the variances of the samples, or to a scalar variance in the case of     1d samples. obsnoise_cov is set to nothing if only a single sample is     provided.\nmean\nsample mean\ndata_names\nnames of the data\n\n\n\n\n\n","category":"type"},{"location":"installation_instructions/#Installation","page":"Installation instructions","title":"Installation","text":"","category":"section"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"To build the top-level project, first clone the repository, then instantiate:","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"cd EnsembleKalmanProcesses.jl\njulia --project -e 'using Pkg; Pkg.instantiate()'","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"To test that the package is working:","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"> julia --project -e 'using Pkg; Pkg.test()'","category":"page"},{"location":"installation_instructions/#Building-the-documentation-locally","page":"Installation instructions","title":"Building the documentation locally","text":"","category":"section"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"Once the project is built, you can build the project documentation under the docs/ sub-project:","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"julia --project=docs/ -e 'using Pkg; Pkg.instantiate()'\njulia --project=docs/ docs/make.jl","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"The locally rendered HTML documentation can be viewed at docs/build/index.html","category":"page"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcessModule","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcessModule","text":"","category":"section"},{"location":"API/EnsembleKalmanProcessModule/","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcessModule","text":"CurrentModule = EnsembleKalmanProcesses.EnsembleKalmanProcessModule","category":"page"},{"location":"API/EnsembleKalmanProcessModule/","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcessModule","text":"Inversion\nSampler\nEnsembleKalmanProcess\nget_u\nget_g\nget_u_final\nget_N_iterations\nconstruct_initial_ensemble\nfind_ekp_stepsize\nupdate_ensemble!","category":"page"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.Inversion","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.Inversion","text":"Inversion <: Process\n\nAn ensemble Kalman Inversion process\n\n\n\n\n\n","category":"type"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.Sampler","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.Sampler","text":"Sampler{FT<:AbstractFloat,IT<:Int} <: Process\n\nAn ensemble Kalman Sampler process\n\n\n\n\n\n","category":"type"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.EnsembleKalmanProcess","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.EnsembleKalmanProcess","text":"EnsembleKalmanProcess{FT<:AbstractFloat, IT<:Int}\n\nStructure that is used in Ensemble Kalman processes\n\n#Fields\n\nu\nArray of stores for parameters (u), each of size [Npar × Nens]\nobs_mean\nvector of the observed vector size [N_obs]\nobs_noise_cov\ncovariance matrix of the observational noise, of size [Nobs × Nobs]\nN_ens\nensemble size\ng\nArray of stores for forward model outputs, each of size  [Nobs × Nens]\nerr\nvector of errors\nΔt\nvector of timesteps used in each EK iteration\nprocess\nthe particular EK process (Inversion or Sampler or Unscented)\n\n\n\n\n\n","category":"type"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.get_u","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.get_u","text":"get_u(ekp::EnsembleKalmanProcess, iteration::IT; return_array=true) where {IT <: Integer}\n\nGet for the EKI iteration. Returns a DataContainer object unless array is specified.\n\n\n\n\n\nget_u(ekp::EnsembleKalmanProcess; return_array=true)\n\nGet for the EKI iteration. Returns a DataContainer object unless array is specified.\n\n\n\n\n\n","category":"function"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.get_g","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.get_g","text":"get_g(ekp::EnsembleKalmanProcess, iteration::IT; return_array=true) where {IT <: Integer}\n\nGet for the EKI iteration. Returns a DataContainer object unless array is specified.\n\n\n\n\n\nget_g(ekp::EnsembleKalmanProcess; return_array=true)\n\nGet for the EKI iteration. Returns a DataContainer object unless array is specified.\n\n\n\n\n\n","category":"function"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.get_u_final","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.get_u_final","text":"get_u_final(ekp::EnsembleKalmanProcess, return_array=true)\n\nGet the final or prior iteration of parameters or model ouputs, returns a DataContainer Object if return_array is false.\n\n\n\n\n\n","category":"function"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.get_N_iterations","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.get_N_iterations","text":"get_N_iterations(ekp::EnsembleKalmanProcess\n\nget number of times update has been called (equals size(g), or size(u)-1) \n\n\n\n\n\n","category":"function"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.construct_initial_ensemble","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.construct_initial_ensemble","text":"construct_initial_ensemble(prior::ParameterDistribution, N_ens::IT; rng_seed=42) where {IT<:Int}\n\nConstruct the initial parameters, by sampling N_ens samples from specified prior distribution. Returned with parameters as columns\n\n\n\n\n\n","category":"function"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.find_ekp_stepsize","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.find_ekp_stepsize","text":"findekpstepsize(ekp::EnsembleKalmanProcess{FT, IT, Inversion}, g::Array{FT, 2}; cov_threshold::FT=0.01) where {FT}\n\nFind largest stepsize for the EK solver that leads to a reduction of the determinant of the sample covariance matrix no greater than cov_threshold. \n\n\n\n\n\n","category":"function"},{"location":"API/EnsembleKalmanProcessModule/#EnsembleKalmanProcesses.EnsembleKalmanProcessModule.update_ensemble!","page":"EnsembleKalmanProcessModule","title":"EnsembleKalmanProcesses.EnsembleKalmanProcessModule.update_ensemble!","text":"update_ensemble!(ekp::EnsembleKalmanProcess{FT, IT, <:Inversion}, g::Array{FT,2} cov_threshold::FT=0.01, Δt_new=nothing) where {FT, IT}\n\nUpdates the ensemble according to which type of Process we have. Model outputs g need to be a Nobs × Nens array (i.e data are columms)\n\n\n\n\n\n","category":"function"},{"location":"parameter_distributions/#Prior-distributions","page":"Prior distributions","title":"Prior distributions","text":"","category":"section"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"We provide a flexible setup for storing prior distribution with the ParameterDistributionStorage module found in src/ParameterDistribution.jl ","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"One can create a full parameter distribution using three inputs.","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"A Distribution, given as a ParameterDistributionType object\nAn array of Constraints, given as a Array{ConstraintType} object\nA Name, given as a String ","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"One can also provide arrays of the triple (1.,2.,3.) to create more complex distributions","category":"page"},{"location":"parameter_distributions/#A-simple-example:","page":"Prior distributions","title":"A simple example:","text":"","category":"section"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"Task: We wish to create a prior for a one-dimensional parameter. Our problem dictates that this parameter is bounded between 0 and 1. Prior knowledge dictates it is around 0.7. The parameter is called \"point_seven\".","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"Solution: We should use a Normal distribution with the predefined \"bounded\" constraint.","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"Let's initialize the constraint first,","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"constraint = [bounded(0,1)] # Sets up a logit-transformation into [0,1].","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"The prior is around 0.7, and the push forward of a normal distribution N(mean=1,sd=0.5) gives a prior with 95% of it's mass between [0.5,0.88].","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"distribution = Parameterized(Normal(1,0.5)) ","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"Finally we attach the name","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"name = \"point_seven\"","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"And the distribution is created by calling:","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"prior = ParameterDistribution(distribution,constraint,name)","category":"page"},{"location":"parameter_distributions/#.-The-ParameterDistributionType","page":"Prior distributions","title":"1. The ParameterDistributionType","text":"","category":"section"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"The ParameterDistributionType has 2 flavours for building a distribution.","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"The Parameterized type is initialized using a Julia Distributions.jl object. Samples are drawn randomly from the distribution object\nThe Samples type is initialized using a two dimensional array. Samples are drawn randomly (with replacement) from the columns of the provided array","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"One can use combinations of these distributions to construct a full parameter distribution.","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"note: Note\nWe recommend these distributions be unbounded (see about constraints below), as our methods do not preserve constraints directly.","category":"page"},{"location":"parameter_distributions/#.-The-ConstraintType","page":"Prior distributions","title":"2. The ConstraintType","text":"","category":"section"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"Our implemented algorithms do not work in constrained parameter space directly. Therefore, constraints are tackled by the mappings transform_constrained_to_unconstrained and transform_unconstrained_to_constrained. The mappings are built from either predefined or user-defined constraint functions held in the ConstraintType. ","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"In this section we call parameters are one-dimensional. Every parameter must have an associated independent ConstraintType, therefore we for each ParameterDistributionType of dimension p the user must provide a p-dimensional Array{ConstraintType}.","category":"page"},{"location":"parameter_distributions/#Predefined-ConstraintTypes","page":"Prior distributions","title":"Predefined ConstraintTypes","text":"","category":"section"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"We provide some ConstraintTypes, which apply different transformations internally to enforce bounds on physical parameter spaces. The types have the following constructors","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"no_constraint(), no transform is required for this parameter\nbounded_below(lower_bound), the physical parameter has a (provided) lower bound\nbounded_above(upper_bound), the physical parameter has a (provided) upper bound \nbounded(lower_bound,upper_bound), the physical parameter has the (provided) bounds","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"Users can also define their own transformations by directly creating a ConstraintType object with their own mappings.","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"note: Note\nIt is up to the user to ensure their provided transforms are inverses of each other.","category":"page"},{"location":"parameter_distributions/#.-The-name","page":"Prior distributions","title":"3. The name","text":"","category":"section"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"This is simply an identifier for the parameters later on.","category":"page"},{"location":"parameter_distributions/#A-more-involved-example:","page":"Prior distributions","title":"A more involved example:","text":"","category":"section"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"We create a 6-dimensional parameter distribution from 2 triples.","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"The first triple is a 4-dimensional distribution with the following constraints on parameters in physical space:","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"c1 = [no_constraint(), # no constraints\n      bounded_below(-1.0), # provide lower bound\n      bounded_above(0.4), # provide upper bound\n      bounded(-0.1,0.2)] # provide lower and upper bound","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"We choose to use a multivariate normal to represent its distribution in the transformed (unbounded) space. Here we take a tridiagonal covariance matrix.","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"diag_val = 0.5*ones(4)\nudiag_val = 0.25*ones(3)\nmean = ones(4)\ncovariance = SymTridiagonal(diagonal_val, udiag_val)\nd1 = Parameterized(MvNormal(mean,covariance)) # 4D multivariate normal","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"We also provide a name","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"name1 = \"constrained_mvnormal\"","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"The second triple is a 2-dimensional one. It is only given by 4 samples in the transformed space - (where one will typically generate samples). It is bounded in the first dimension by the constraint shown, there is a user provided transform for the second dimension - using the default constructor.","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"d2 = Samples([1.0 3.0; 5.0 7.0; 9.0 11.0; 13.0 15.0]) # 4 samples of 2D parameter space\ntransform = (x -> 3*x + 14)\ninverse_transform = (x -> (x-14) / 3)\nc2 = [bounded(10,15),\n      Constraint(transform, inverse_transform)]\nname2 = \"constrained_sampled\"","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"The full prior distribution for this setting is created with arrays of our two triples","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"u = ParameterDistribution([d1,d2],[c1,c2],[name1,name2])","category":"page"},{"location":"parameter_distributions/#Other-functions","page":"Prior distributions","title":"Other functions","text":"","category":"section"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"These functions typically return a Dict with ParameterDistribution.name as a keys, or an Array if requested ","category":"page"},{"location":"parameter_distributions/","page":"Prior distributions","title":"Prior distributions","text":"get_name: returns the names\nget_distribution: returns the Julia Distribution object if it is Parameterized\nsample_distribution: samples the Julia Distribution if Parameterized, or draws from the list of samples if Samples\ntransform_unconstrained_to_constrained: Apply the constraint mappings\ntransform_constrained_to_unconstrained: Apply the inverse constraint mappings ","category":"page"},{"location":"glossary/#Glossary","page":"Glossary","title":"Glossary","text":"","category":"section"},{"location":"glossary/","page":"Glossary","title":"Glossary","text":"The following list includes the names and symbols of recurring concepts in EnsembleKalmanProcesses.jl. Some of these variables do not appear in the codebase, which relies on array programming for performance.  Contributions to the codebase require following this notational convention. Similarly, if you find inconsistencies in the documentation or codebase, please report an issue on GitHub.","category":"page"},{"location":"glossary/","page":"Glossary","title":"Glossary","text":"Name Symbol (Theory/Docs) Symbol (Code)\nParameter vector, Parameters (unconstrained space) theta theta\nParameter vector size, Number of parameters p N_par\nEnsemble size J N_ens\nEnsemble particles, members theta^(j) \nNumber of iterations N_it N_iter\nObservation vector, Observations, Data vector y y\nObservation vector size, Data vector size d N_obs\nObservational noise eta obs_noise\nObservational noise covariance Gamma_y obs_noise_cov\nHilbert space inner product langle phi Gamma^-1 psirangle \nForward map mathcalG G\nDynamical model Psi Psi\nTransform map (constrained to unconstrained) mathcalT T\nObservation map mathcalH H\nPrior covariance (unconstrained space) Gamma_theta prior_cov\nPrior mean (unconstrained space) m_theta prior_mean","category":"page"},{"location":"examples/lorenz_example/#Lorenz-96-example","page":"Lorenz Example","title":"Lorenz 96 example","text":"","category":"section"},{"location":"examples/lorenz_example/#Overview","page":"Lorenz Example","title":"Overview","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The Lorenz 96 (hereafter L96) example is a toy-problem for the application of the EnsembleKalmanProcesses.jl optimization and approximate uncertainty quantification methodologies. Here is L96 with additional periodic-in-time forcing, we try to determine parameters (sinusoidal amplitude and stationary component of the forcing) from some output statistics. The standard L96 equations are implemented with an additional forcing term with time dependence. The output statistics which are used for learning are the finite time-averaged variances.","category":"page"},{"location":"examples/lorenz_example/#Lorenz-96-equations","page":"Lorenz Example","title":"Lorenz 96 equations","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The standard single-scale L96 equations are implemented. The Lorenz 96 system (Lorenz, 1996) is given by ","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"fracd x_id t = (x_i+1 - x_i-2) x_i-1 - x_i + F","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"with i indicating the index of the given longitude. The number of longitudes is given by N. The boundary conditions are given by","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"x_-1 = x_N-1  x_0 = x_N  x_N+1 = x_1","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The time scaling is such that the characteristic time is 5 days (Lorenz, 1996).  For very small values of F, the solutions x_i decay to F after the initial transient feature. For moderate values of F, the solutions are periodic, and for larger values of F, the system is chaotic. The solution variance is a function of the forcing magnitude. Variations in the base state as a function of time can be imposed through a time-dependent forcing term F(t).","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"A temporal forcing term is defined","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"F = F_s + A sin(omega t)","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"with steady-state forcing F_s, transient forcing amplitude A, and transient forcing frequency omega. The total forcing F must be within the chaotic regime of L96 for all time given the prescribed N.","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The L96 dynamics are solved with RK4 integration.","category":"page"},{"location":"examples/lorenz_example/#Structure","page":"Lorenz Example","title":"Structure","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The main code is located in Lorenz_example.jl which provides the functionality to run the L96 dynamical system, extract time-averaged statistics from the L96 states, and use the time-average statistics for optimization and uncertainty quantification.","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The L96 system is solved in GModel.jl according to the time integration settings specified in LSettings and the L96 parameters specified in LParams. The types of statistics to be collected are detailed in GModel.jl.","category":"page"},{"location":"examples/lorenz_example/#Lorenz-dynamics-inputs","page":"Lorenz Example","title":"Lorenz dynamics inputs","text":"","category":"section"},{"location":"examples/lorenz_example/#Dynamics-settings","page":"Lorenz Example","title":"Dynamics settings","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The use of the transient forcing term is with the flag, dynamics. Stationary forcing is dynamics=1 (A=0) and transient forcing is used with dynamics=2 (Aneq0). The default parameters are specified in Lorenz_example.jl and can be modified as necessary. The system is solved over time horizon 0 to tend at fixed time step dt.","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"N = 36\ndt = 1/64\nt_start = 800","category":"page"},{"location":"examples/lorenz_example/#Inverse-problem-settings","page":"Lorenz Example","title":"Inverse problem settings","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The states are integrated over time Ts_days to construct the time averaged statistics for use by the optimization. The specification of the statistics to be gathered from the states are provided by stats_type. The Ensemble Kalman Process (EKP) settings are","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"N_ens = 20 # number of ensemble members\nN_iter = 5 # number of EKI iterations","category":"page"},{"location":"examples/lorenz_example/#Setting-up-the-Inverse-Problem","page":"Lorenz Example","title":"Setting up the Inverse Problem","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The goal is to learn F_s and A based on the time averaged statistics in a perfect model setting. The true parameters are","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"F_true = 8. # Mean F\nA_true = 2.5 # Transient F amplitude\nω_true = 2. * π / (360. / τc) # Frequency of the transient F\nparams_true = [F_true, A_true]\nparam_names = [\"F\", \"A\"]","category":"page"},{"location":"examples/lorenz_example/#Priors","page":"Lorenz Example","title":"Priors","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"We use normal priors without constraints","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"prior_means = [F_true+1.0, A_true+0.5]\nprior_stds = [2.0, 0.5*A_true]\nd1 = Parameterized(Normal(prior_means[1], prior_stds[1]))\nd2 = Parameterized(Normal(prior_means[2], prior_stds[2]))\nprior_distns = [d1, d2]\nc1 = no_constraint()\nc2 = no_constraint()\nconstraints = [[c1], [c2]]\nprior_names = param_names\npriors = ParameterDistribution(prior_distns, constraints, prior_names)","category":"page"},{"location":"examples/lorenz_example/#Observational-Noise","page":"Lorenz Example","title":"Observational Noise","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The observational noise can be generated using the L96 system or prescribed, as specified by var_prescribe. ","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"var_prescribe==false The observational noise is constructed by generating independent instantiations of the L96 statistics of interest at the true parameters for different initial conditions. The empirical covariance matrix is constructed.","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"var_prescribe==true The observational noise is prescribed as a Gaussian distribution with prescribed mean and variance.","category":"page"},{"location":"examples/lorenz_example/#Running-the-Example","page":"Lorenz Example","title":"Running the Example","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The L96 parameter estimation can be run using julia --project Lorenz_example.jl","category":"page"},{"location":"examples/lorenz_example/#Solution-and-Output","page":"Lorenz Example","title":"Solution and Output","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The output will provide the estimated parameters.","category":"page"},{"location":"examples/lorenz_example/#Printed-output","page":"Lorenz Example","title":"Printed output","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"# EKI results: Has the ensemble collapsed toward the truth?\nprintln(\"True parameters: \")\nprintln(params_true)\nprintln(\"\\nEKI results:\")\nprintln(mean(get_u_final(ekiobj), dims=2))","category":"page"},{"location":"examples/lorenz_example/#Saved-output","page":"Lorenz Example","title":"Saved output","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"The parameters and forward model outputs will be saved in parameter_storage.jld2 and data_storage.jld2, respectively. The data will be saved in the directory output.","category":"page"},{"location":"examples/lorenz_example/#Plots","page":"Lorenz Example","title":"Plots","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz Example","title":"Lorenz Example","text":"A scatter plot of the parameter estimates compared to the true parameters will be provided in the directory output.","category":"page"},{"location":"examples/template_example/#Template-example","page":"Template Example","title":"Template example","text":"","category":"section"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"We provide the following template for how the tools may be applied.","category":"page"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"For small examples typically have 2 files.","category":"page"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"DynamicalModel.jl Contains the dynamical model Psi and the observation map mathcalH. The inputs should be the so-called free parameters (in the constrained/physical space that is the input domain of the dynamical model) we are interested in learning, and the output should be the measured data.\nThe example script which contains the inverse problem setup and solve","category":"page"},{"location":"examples/template_example/#The-structure-of-the-example-script","page":"Template Example","title":"The structure of the example script","text":"","category":"section"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"First we create the data and the setting for the model","category":"page"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"Set up the forward model.\nConstruct/load the truth data. Store this data conveniently in the Observations.Obs object","category":"page"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"Then we set up the inverse problem","category":"page"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"Define the prior distributions. Use the ParameterDistribution object\nDecide on which process tool you would like to use (we recommend you begin with Inversion()). Then initialize this with the relevant constructor\ninitialize the EnsembleKalmanProcess object","category":"page"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"Then we solve the inverse problem, in a loop perform the following for as many iterations as required:","category":"page"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"Obtain the current parameter ensemble\nTransform them from the unbounded computational space to the physical space\ncall the forward map on the ensemble of parameters, producing an ensemble of measured data\ncall the update_ensemble! function to generate a new parameter ensemble based on the new data","category":"page"},{"location":"examples/template_example/","page":"Template Example","title":"Template Example","text":"One can then obtain the solution, dependent on the process type.","category":"page"},{"location":"ensemble_kalman_inversion/#Ensemble-Kalman-Inversion","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"","category":"section"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"One of the ensemble Kalman processes implemented in EnsembleKalmanProcesses.jl is the ensemble Kalman inversion (Iglesias et al, 2013). The ensemble Kalman inversion (EKI) is a derivative-free ensemble optimization method that seeks to find the optimal parameters theta in mathbbR^p in the inverse problem","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"\\[ y = \\mathcal{G}(\\theta) + \\eta, \\]","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"where mathcalG denotes the forward map, y in mathbbR^d is the vector of observations and eta sim mathcalN(0 Gamma_y) is additive Gaussian observational noise. Note that p is the size of the parameter vector theta and d is taken to be the size of the observation vector y. The EKI update equation for parameter vector theta^(j) of ensemble member j is","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"theta_n+1^(j) = theta_n^(j) - dfracDelta t_nJsum_k=1^Jlangle mathcalG(theta_n^(k)) - barmathcalG_n Gamma_y^-1(mathcalG(theta_n^(j)) - y) rangle theta_n^(k)","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"where the subscript n=1 dots N_it indicates the iteration, J is the number of members in the ensemble and barmathcalG_n is the mean value of mathcalG(theta) across ensemble members,","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"barmathcalG_n = dfrac1Jsum_k=1^JmathcalG(theta_n^(k))","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"The EKI algorithm is considered converged when the ensemble achieves sufficient consensus/collapse in parameter space. The final estimate bartheta_N_it is taken to be the ensemble mean at the final iteration,","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"bartheta_N_it = dfrac1Jsum_k=1^Jtheta_N_it^(k)","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"For typical applications, a near-optimal solution theta can be found after as few as 10 iterations of the algorithm. The obtained solution is optimal in the sense of the mean squared error loss, details can be found in Iglesias et al (2013). The algorithm performs better with larger ensembles. As a rule of thumb, the number of members in the ensemble should be larger than 10p, although the optimal ensemble size may depend on the problem setting and the computational power available.","category":"page"},{"location":"ensemble_kalman_inversion/#Constructing-the-Forward-Map","page":"Ensemble Kalman Inversion","title":"Constructing the Forward Map","text":"","category":"section"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"The forward map mathcalG maps the space of unconstrained parameters theta in mathbbR^p to the outputs yin mathbbR^d. In practice, the user may not have access to such a map directly. Consider a situation where the goal is to learn a set of parameters phi of a dynamical model PsimathbbR^p rightarrow mathbbR^o, given observations y in mathbbR^d and a set of constraints on the value of phi. Then, the forward map may be constructed as","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"mathcalG = mathcalH circ Psi circ mathcalT^-1","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"where mathcalHmathbbR^o rightarrow mathbbR^d is the observation map and mathcalT is the transformation map from constrained to unconstrained parameter spaces, such that mathcalT(phi)=theta. A family of standard transformation maps and their inverse are available in the ParameterDistributionStorage module.","category":"page"},{"location":"ensemble_kalman_inversion/#Creating-the-EKI-Object","page":"Ensemble Kalman Inversion","title":"Creating the EKI Object","text":"","category":"section"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"An ensemble Kalman inversion object can be created using the EnsembleKalmanProcess constructor by specifying the Inversion() process type.","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"Creating an ensemble Kalman inversion object requires as arguments:","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"An initial parameter ensemble, Array{FT, 2} of size [p × J];\nThe mean value of the observed outputs, a vector of size [d];\nThe covariance of the observational noise, a matrix of size [d × d]\nThe Inversion() process type.","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"A typical initialization of the Inversion() process takes a user-defined prior, a summary of the observation statistics given by the mean y and covariance obs_noise_cov, and a desired number of members in the ensemble,","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"using EnsembleKalmanProcesses.EnsembleKalmanProcessModule\nusing EnsembleKalmanProcesses.ParameterDistributionStorage\n\nJ = 50  # number of ensemble members\ninitial_ensemble = construct_initial_ensemble(prior, J) # Initialize ensemble from prior\n\nekiobj = EnsembleKalmanProcess(initial_ensemble, y, obs_noise_cov, Inversion())","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"See the Prior distributions section to learn about the construction of priors in EnsembleKalmanProcesses.jl. The prior is assumed to be over the unconstrained parameter space where theta is defined. For applications where enforcing parameter bounds is necessary, the ParameterDistributionStorage module provides functions to map from constrained to unconstrained space and viceversa. ","category":"page"},{"location":"ensemble_kalman_inversion/#Updating-the-Ensemble","page":"Ensemble Kalman Inversion","title":"Updating the Ensemble","text":"","category":"section"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"Once the ensemble Kalman inversion object ekiobj has been initialized, any number of updates can be performed using the inversion algorithm.","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"A call to the inversion algorithm can be performed with the update_ensemble! function. This function takes as arguments the ekiobj and the evaluations of the forward map at each member of the current ensemble. The update_ensemble! function then stores the new updated ensemble and the inputted forward map evaluations in ekiobj. ","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"A typical use of the update_ensemble! function given the ensemble Kalman inversion object ekiobj, the dynamical model Ψ and the observation map H is","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"N_iter = 20 # Number of steps of the algorithm\n\nfor n in 1:N_iter\n    θ_n = get_u_final(ekiobj) # Get current ensemble\n    ϕ_n = transform_unconstrained_to_constrained(prior, θ_n) # Transform parameters to physical/constrained space\n    G_n = [ H( Ψ((ϕ_n[:,i]) ) for i in 1:J]\n    g_ens = hcat(G_n...) # Evaluate forward map\n    update_ensemble!(ekiobj, g_ens) # Update ensemble\nend","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"In the previous update, note that the parameters stored in ekiobj are given in the unconstrained Gaussian space where the EKI algorithm is performed. The map mathcalT^-1 between this unconstrained space and the (possibly constrained) physical space of parameters is encoded in the prior object. The dynamical model Ψ accepts as inputs the parameters in (possibly constrained) physical space, so it is necessary to apply transform_unconstrained_to_constrained before evaluations. See the Prior distributions section for more details on parameter transformations.","category":"page"},{"location":"ensemble_kalman_inversion/#Solution","page":"Ensemble Kalman Inversion","title":"Solution","text":"","category":"section"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"The EKI algorithm drives the initial ensemble, sampled from the prior, towards the support region of the posterior distribution. The algorithm also drives the ensemble members towards consensus. The optimal parameter θ_optim found by the algorithm is given by the mean of the last ensemble (i.e., the ensemble after the last iteration),","category":"page"},{"location":"ensemble_kalman_inversion/","page":"Ensemble Kalman Inversion","title":"Ensemble Kalman Inversion","text":"using Statistics\n\nθ_optim = mean(get_u_final(ekiobj), dims=2)","category":"page"},{"location":"API/ParameterDistribution/#ParameterDistribution","page":"ParameterDistribution","title":"ParameterDistribution","text":"","category":"section"},{"location":"API/ParameterDistribution/","page":"ParameterDistribution","title":"ParameterDistribution","text":"CurrentModule = EnsembleKalmanProcesses.ParameterDistributionStorage","category":"page"},{"location":"API/ParameterDistribution/","page":"ParameterDistribution","title":"ParameterDistribution","text":"Parameterized\nSamples\nConstraint\nno_constraint\nbounded_below\nbounded_above\nbounded\nlen\nn_samples\nParameterDistribution\nget_name\nget_dimensions\nget_n_samples\nget_all_constraints\nbatch\nget_distribution\nsample_distribution\nget_logpdf\nget_cov\nget_mean\ntransform_constrained_to_unconstrained\ntransform_unconstrained_to_constrained","category":"page"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.Parameterized","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.Parameterized","text":"struct Parameterized <: ParameterDistributionType\n\nA distribution constructed from a parametrized formula (e.g Julia Distributions.jl)\n\n\n\n\n\n","category":"type"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.Samples","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.Samples","text":"struct Samples{FT<:Real} <: ParameterDistributionType\n\nA distribution comprised of only samples, stored as columns of parameters\n\n\n\n\n\n","category":"type"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.Constraint","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.Constraint","text":"struct Constraint <: ConstraintType\n\nContains two functions to map between constrained and unconstrained spaces.\n\n\n\n\n\n","category":"type"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.no_constraint","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.no_constraint","text":"function no_constraint()\n\nConstructs a Constraint with no constraints, enforced by maps x -> x and x -> x.\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.bounded_below","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.bounded_below","text":"function bounded_below(lower_bound::FT) where {FT <: Real}\n\nConstructs a Constraint with provided lower bound, enforced by maps x -> log(x - lowerbound) and x -> exp(x) + lowerbound.\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.bounded_above","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.bounded_above","text":"function bounded_above(upper_bound::FT) where {FT <: Real}\n\nConstructs a Constraint with provided upper bound, enforced by maps x -> log(upperbound - x) and x -> upperbound - exp(x).\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.bounded","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.bounded","text":"function bounded(lower_bound::FT, upper_bound::FT) where {FT <: Real}\n\nConstructs a Constraint with provided upper and lower bounds, enforced by maps x -> log((x - lowerbound) / (upperbound - x)) and x -> (upperbound * exp(x) + lowerbound) / (exp(x) + 1)\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.len","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.len","text":"function len(c::Array{CType})\n\nThe number of constraints, each constraint has length 1.\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.n_samples","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.n_samples","text":"function n_samples(d::Samples)\n\nThe number of samples in the array\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.ParameterDistribution","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.ParameterDistribution","text":"struct ParameterDistribution\n\nStructure to hold a parameter distribution, always stored as an array of distributions\n\n\n\n\n\n","category":"type"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.get_name","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.get_name","text":"function get_name(pd::ParameterDistribution)\n\nReturns a list of ParameterDistribution names\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.get_dimensions","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.get_dimensions","text":"function get_dimensions(pd::ParameterDistribution)\n\nThe number of dimensions of the parameter space\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.get_n_samples","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.get_n_samples","text":"function get_n_samples(pd::ParameterDistribution)\n\nThe number of samples in a Samples distribution\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.get_all_constraints","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.get_all_constraints","text":"function get_all_constraints(pd::ParameterDistribution)\n\nreturns the (flattened) array of constraints of the parameter distribution\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.batch","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.batch","text":"function batch(pd:ParameterDistribution)\n\nReturns a list of contiguous [collect(1:i), collect(i+1:j),... ] used to split parameter arrays by distribution dimensions\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.get_distribution","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.get_distribution","text":"function get_distribution(pd::ParameterDistribution)\n\nReturns a Dict of ParameterDistribution distributions, with the parameter names as dictionary keys. For parameters represented by Samples, the samples are returned as a 2D (parameterdimension x nsamples) array\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.sample_distribution","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.sample_distribution","text":"function sample_distribution(pd::ParameterDistribution)\n\nDraws samples from the parameter distributions returns an array, with parameters as columns\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.get_logpdf","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.get_logpdf","text":"function logpdf(pd::ParameterDistribution, xarray::Array{<:Real,1})\n\nObtains the independent logpdfs of the parameter distributions at xarray (non-Samples Distributions only), and returns their sum.\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.get_cov","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.get_cov","text":"function get_cov(pd::ParameterDistribution)\n\nreturns a blocked covariance of the distributions\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.get_mean","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.get_mean","text":"get_mean(pd::Parameterized)\n\nreturns a mean of parameterized distribution\n\n\n\n\n\nget_mean(pd::Samples)\n\nreturns a mean of the samples\n\n\n\n\n\nfunction get_mean(pd::ParameterDistribution)\n\nreturns a mean of the distributions\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.transform_constrained_to_unconstrained","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.transform_constrained_to_unconstrained","text":"function transform_constrained_to_unconstrained(pd::ParameterDistribution, x::Array{<:Real})\n\nApply the transformation to map (possibly constrained) parameters xarray into the unconstrained space\n\n\n\n\n\n","category":"function"},{"location":"API/ParameterDistribution/#EnsembleKalmanProcesses.ParameterDistributionStorage.transform_unconstrained_to_constrained","page":"ParameterDistribution","title":"EnsembleKalmanProcesses.ParameterDistributionStorage.transform_unconstrained_to_constrained","text":"function transform_unconstrained_to_constrained(pd::ParameterDistribution, xarray::Array{Real})\n\nApply the transformation to map parameters xarray from the unconstrained space into (possibly constrained) space\n\n\n\n\n\n","category":"function"},{"location":"examples/ClimateMachine_example/#HPC-interfacing-example:-ClimateMachine","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"","category":"section"},{"location":"examples/ClimateMachine_example/#Overview","page":"HPC interfacing example: ClimateMachine","title":"Overview","text":"","category":"section"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"This examples uses EnsembleKalmanProcesses.jl to calibrate a climate model, showcasing a workflow which is compatible with HPC resources managed with the SLURM workload manager. The workflow is based on read-write input/output files, and as such it is capable of interfacing with dynamical models in different code languages, or with complicated processing stages. The dynamical model for this example is ClimateMachine.jl, an Earth system model currently under development at CliMA.","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"The calibration example makes use of a simple single atmospheric column model configuration with two learnable parameters that control turbulent mixing processes in the lower troposphere. It is also a perfect model experiment, in the sense that the ground truth is generated using the same model and a prescribed combination of parameters. The parameters used to generate the ground truth are (C_smag, C_drag) = (0.21, 0.0011). The evolution of the atmosphere for this setup is strongly influenced by C_smag, and very weakly by C_drag. Thus, we expect the EKP to recover C_smag from observations.","category":"page"},{"location":"examples/ClimateMachine_example/#Prerequisites","page":"HPC interfacing example: ClimateMachine","title":"Prerequisites","text":"","category":"section"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"This example requires ClimateMachine.jl to be installed in the same parent directory as EnsembleKalmanProcesses.jl. You may install ClimateMachine.jl directly from GitHub,","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"$ git clone https://github.com/CliMA/ClimateMachine.jl.git","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"Change into the ClimateMachine.jl directory with ","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"$ cd ClimateMachine.jl","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"and install all the required packages with:","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"$ julia --project -e 'using Pkg; pkg\"instantiate\";'","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"Pre-compile the packages to allow the ClimateMachine.jl to start faster:","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"$ julia --project -e 'using Pkg; pkg\"precompile\"'","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"You can find more information about ClimateMachine.jl here. ClimateMachine.jl is a rapidly evolving software and this example may stop working in the future, please open an issue if you find that to be the case!","category":"page"},{"location":"examples/ClimateMachine_example/#Structure","page":"HPC interfacing example: ClimateMachine","title":"Structure","text":"","category":"section"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"The example makes use of julia and bash scripts for interactions with the workload manager and running multiple forward model evaluations in parallel. The user-triggered script ekp_calibration.sbatch initializes and controls the flow of the calibration process, which in this case is a SLURM queue with job dependencies. The calibration bash scripts, in order of execution and with their associated julia scripts, are","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"ekp_init_calibration: Calls init_calibration.jl, which samples the initial parameter ensemble from a specified prior. The initial ensemble is stored in a set of parameter files.\nekp_single_cm_run: Script called in parallel by the workload manager. Each copy of the script submits a single forward model run (i.e., a ClimateMachine.jl run) given a specific pair of parameters (C_smag, C_drag) read from a corresponding file. The output of each forward model run is stored in a separate NetCDF file.\nekp_cont_calibration: Calls sstep_calibration.jl, which reads from a NetCDF file the output generated by ClimateMachine.jl in step 2 and performs an iteration of the Ensemble Kalman Inversion algorithm, updating the parameter ensemble. The new parameters are stored in new parameter files.","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"This flow follows steps 1->2->3->2->3->... for a user-specified number of iterations.","category":"page"},{"location":"examples/ClimateMachine_example/#Running-the-Example","page":"HPC interfacing example: ClimateMachine","title":"Running the Example","text":"","category":"section"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"From the parent directory of ClimateMachine.jl and EnsembleKalmanProcesses.jl, change into the example directory with","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"$ cd EnsembleKalmanProcesses.jl/examples/ClimateMachine","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"and install all the required packages for the example with:","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"$ julia --project -e 'using Pkg; pkg\"instantiate\";'","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"To run the example using a SLURM workload manager, simply do:","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"$ sbatch ekp_calibration.sbatch","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"The dynamical model outputs (i.e, Psi(phi)) for all runs of ClimateMachine.jl will be stored in NetCDF format in directories identifiable by their version number. Refer to the files version_XX.txt to identify each run with each ensemble member within the XX iteration of the Ensemble Kalman Process. ","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"In this example, the parameters are defined through a Gaussian prior in init_calibration.jl. Hence, the transform from constrained to unconstrained space is the identity map, and we have phi=theta. Overall the forward map mathcalG(theta) is given by applying an observation map mathcalH to the dynamical model output Psi. In this case, mathcalH returns the time average of the horizontal velocity over a specified 30 min interval after initialization. Therefore, the observation vector y contains a time-averaged vertical profile of the horizontal velocity.","category":"page"},{"location":"examples/ClimateMachine_example/#Calibration-Solution","page":"HPC interfacing example: ClimateMachine","title":"Calibration Solution","text":"","category":"section"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"To aggregate the parameter ensembles theta^(1) theta^(2) dots theta^(J) generated during the calibration process, you may use the agg_clima_ekp(...) function located in helper_funcs.jl,","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"$ julia --project","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"include(joinpath(@__DIR__, \"helper_funcs.jl\"))\n\nagg_clima_ekp(2) # This generates the output containing the ensembles for each iteration, input is the number of parameters","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"This will create the JLD file ekp_clima.jld. We may read the file as follows","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"using JLD\n\nθ = load(\"ekp_clima.jld\")[\"ekp_u\"]\nprintln(typeof(θ)) # Array{Array{Float64,2},1}, outer dimension is N_iter, inner Array{Float64,2} of size = (J, p)","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"The optimal parameter vector determined by the ensemble Kalman inversion is the ensemble mean of the particles after the last iteration. Following the previous script,","category":"page"},{"location":"examples/ClimateMachine_example/","page":"HPC interfacing example: ClimateMachine","title":"HPC interfacing example: ClimateMachine","text":"using Statistics\n\nθ_opt = mean(θ[end], dims=1)","category":"page"},{"location":"API/EnsembleKalmanProcesses/#EnsembleKalmanProcesses","page":"EnsembleKalmanProcesses","title":"EnsembleKalmanProcesses","text":"","category":"section"},{"location":"API/EnsembleKalmanProcesses/","page":"EnsembleKalmanProcesses","title":"EnsembleKalmanProcesses","text":"CurrentModule = EnsembleKalmanProcesses","category":"page"},{"location":"API/EnsembleKalmanProcesses/","page":"EnsembleKalmanProcesses","title":"EnsembleKalmanProcesses","text":"","category":"page"},{"location":"unscented_kalman_inversion/#Unscented-Kalman-Inversion","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"","category":"section"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"One of the ensemble Kalman processes implemented in EnsembleKalmanProcesses.jl is the unscented Kalman inversion (Huang et al, 2021). The unscented Kalman inversion (UKI) is a derivative-free ensemble optimization method that seeks to find the optimal parameters theta in mathbbR^p in the inverse problem","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":" y = mathcalG(theta) + eta","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"where mathcalG denotes the forward map, y in mathbbR^d is the vector of observations and eta sim mathcalN(0 Gamma_y) is additive Gaussian observational noise. Note that p is the size of the parameter vector theta and d is taken to be the size of the observation vector y. The UKI algorithm has the following properties","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"UKI has a given ensemble size and requires only 2p + 1 particles in general.\nUKI has uncertainty quantification capability, it gives both mean and covariance approximation (no ensemble collapse and no empirical variance inflation) of the posterior distribution, the 3-sigma confidence interval covers the truth parameters for perfect models.","category":"page"},{"location":"unscented_kalman_inversion/#Algorithm","page":"Unscented Kalman Inversion","title":"Algorithm","text":"","category":"section"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"The UKI applies unscented Kalman filter for the following stochastic dynamical system ","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"beginaligned\n  textrmevolution    theta_n+1 = r + alpha (theta_n  - r) +  omega_n+1 omega_n+1 sim mathcalN(0Sigma_omega)\n  textrmobservation  y_n+1 = mathcalG(theta_n+1) + nu_n+1 nu_n+1 sim mathcalN(0Sigma_nu)\nendaligned","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"The free parameters in the UKI are alpha r Sigma_nu Sigma_omega. The UKI updates both the mean m_n and covariance C_n estimations of the parameter vector theta as following","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"Prediction step :","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"beginaligned\n    hatm_n+1 =  r+alpha(m_n-r)\n    hatC_n+1 =  alpha^2 C_n + Sigma_omega\nendaligned","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"Generate sigma points :","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"beginaligned\n    hattheta_n+1^0 = hatm_n+1 \n    hattheta_n+1^j = hatm_n+1 + c_j sqrthatC_n+1_j quad (1leq jleq N_theta) \n    hattheta_n+1^j+N_theta = hatm_n+1 - c_j sqrthatC_n+1_jquad (1leq jleq N_theta)\nendaligned","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"Analysis step :","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"   beginaligned\n        haty^j_n+1 = mathcalG(hattheta^j_n+1) qquad haty_n+1 = haty^0_n+1\n         hatC^theta p_n+1 = sum_j=1^2N_thetaW_j^c\n        (hattheta^j_n+1 - hatm_n+1 )(haty^j_n+1 - haty_n+1)^T \n        hatC^pp_n+1 = sum_j=1^2N_thetaW_j^c\n        (haty^j_n+1 - haty_n+1 )(haty^j_n+1 - haty_n+1)^T + Sigma_nu\n        m_n+1 = hatm_n+1 + hatC^theta p_n+1(hatC^pp_n+1)^-1(y - haty_n+1)\n        C_n+1 = hatC_n+1 - hatC^theta p_n+1(hatC^pp_n+1)^-1hatC^theta p_n+1^T\n    endaligned","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"The unscented transformation parameters are","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"    beginaligned\n    c_j = sqrtN_theta +lambda qquad W_j^c = frac12(N_theta+lambda)(j=1cdots2N_theta)\n    lambda = a^2 (N_theta + kappa) - N_theta quad a=minsqrtfrac4N_theta + kappa  1quad  kappa = 0\n    endaligned","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"And sqrtC_j is the jth column of the Cholesky factor of C. ","category":"page"},{"location":"unscented_kalman_inversion/#Choosing-of-free-parameters","page":"Unscented Kalman Inversion","title":"Choosing of free parameters","text":"","category":"section"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"The free parameters in the unscented Kalman inversion are alpha r Sigma_nu Sigma_omega, which are chosen based on theorems developed in Huang et al, 2021","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"the vector r is set to be the prior mean\nthe scalar alpha in (01 is a regularization parameter, which is used to overcome ill-posedness and overfitting. A practical guide is \nWhen the observation noise is negligible, and there are more observations than parameters (identifiable inverse problem) alpha = 1 (no regularization)\nOtherwise alpha  1. The smaller alpha is, the closer UKI will converge to the prior mean.\nthe matrix Sigma_nu is the artificial observation error covariance. We set Sigma_nu = 2 Gamma_y, which makes the inverse problem consistent. \nthe matrix Sigma_omega is the artificial evolution error covariance. We set Sigma_omega = (2 - alpha^2)Lambda. We choose Lambda as following\nwhen there are more observations than parameters (identifiable inverse problem), Lambda = C_n, which is updated as the estimated covariance C_n in the n-thevery iteration . This guarantees the converged covariance matrix is a good approximation to the posterior covariance matrix with an uninformative prior.\notherwise Lambda = C_0, this allows that the converged covariance matrix is a weighted average between the posterior covariance matrix with an uninformative prior and C_0.","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"In a nutshell, users only need to change the alpha (α_reg), and the freqency to update the Lambda (update_freq). The user can first try α_reg = 1.0 and update_freq = 0.","category":"page"},{"location":"unscented_kalman_inversion/#Implementation","page":"Unscented Kalman Inversion","title":"Implementation","text":"","category":"section"},{"location":"unscented_kalman_inversion/#Initialization","page":"Unscented Kalman Inversion","title":"Initialization","text":"","category":"section"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"An unscented Kalman inversion object can be created using the EnsembleKalmanProcess constructor by specifying the Unscented() process type.","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"Creating an ensemble Kalman inversion object requires as arguments:","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"The mean value of the observed outputs, a vector of size [d];\nThe covariance of the observational noise, a matrix of size [d × d];\nThe Unscented() process type.","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"The initialization of the Unscented() process requires prior mean and prior covariance, and the the size of the observation d. And user defined hyperparameters  α_reg and update_freq.","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"using EnsembleKalmanProcesses.EnsembleKalmanProcessModule\nusing EnsembleKalmanProcesses.ParameterDistributionStorage\n\n\n# need to choose regularization factor α ∈ (0,1],  \n# when you have enough observation data α=1: no regularization\nα_reg =  1.0\n# update_freq 1 : approximate posterior covariance matrix with an uninformative prior\n#             0 : weighted average between posterior covariance matrix with an uninformative prior and prior\nupdate_freq = 0\n\nprocess = Unscented(prior_mean, prior_cov, length(truth_sample), α_reg, update_freq)\nukiobj = EnsembleKalmanProcessModule.EnsembleKalmanProcess(truth_sample, truth.obs_noise_cov, process)\n","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"Note that no information about the forward map is necessary to initialize the Inversion process. The only forward map information required by the inversion process consists of model evaluations at the ensemble elements, necessary to update the ensemble.","category":"page"},{"location":"unscented_kalman_inversion/#Constructing-the-Forward-Map","page":"Unscented Kalman Inversion","title":"Constructing the Forward Map","text":"","category":"section"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"At the core of the forward map mathcalG is the dynamical model PsimathbbR^p rightarrow mathbbR^o (running Psi is usually where the computational heavy-lifting is done), but the map mathcalG may include additional components such as a transformation of the (unbounded) parameters theta to a constrained domain the dynamical model can work with, or some post-processing of the output of Psi to generate the observations. For example, mathcalG may take the following form:","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"mathcalG = mathcalH circ Psi circ mathcalT^-1","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"where mathcalHmathbbR^o rightarrow mathbbR^d is the observation map and mathcalT is the transformation from the constrained to the unconstrained parameter space, such that mathcalT(phi)=theta. A family of standard transformations and their inverses are available in the ParameterDistributionStorage module.","category":"page"},{"location":"unscented_kalman_inversion/#Updating-the-Ensemble","page":"Unscented Kalman Inversion","title":"Updating the Ensemble","text":"","category":"section"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"Once the unscented Kalman inversion object UKIobj has been initialized, any number of updates can be performed using the inversion algorithm.","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"A call to the inversion algorithm can be performed with the update_ensemble! function. This function takes as arguments the UKIobj and the evaluations of the forward map at each element of the current ensemble. The update_ensemble! function then stores the new updated ensemble and the inputted forward map evaluations in UKIobj.","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"The forward map mathcalG maps the space of unconstrained parameters theta to the outputs yin mathbbR^d. In practice, the user may not have access to such a map directly. And the map is a composition of several functions. The update_ensemble! uses only the evalutaions g_ens but not the forward map  ","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"For implementational reasons, the update_ensemble is performed by computing analysis stage first, followed by a prediction of the next sigma ensemble. And the first prediction is done in the initialization.","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"N_iter = 20 # Number of steps of the algorithm\n \nfor n in 1:N_iter\n\n    # define black box parameter to observation map, \n    # with certain parameter transformation related to imposing some constraints\n    # i.e. θ -> e^θ  -> G(e^θ) = y\n    θ_n = get_u_final(ukiobj) # Get current ensemble\n    ϕ_n = transform_unconstrained_to_constrained(prior, θ_n) # Transform parameters to physical/constrained space\n    G_n = [H(Ψ(ϕ_n[:, i])) for i in 1:J]  # Evaluate forward map\n    g_ens = hcat(G_n...)  # Reformat into `d x N_ens` matrix\n    EnsembleKalmanProcessModule.update_ensemble!(ukiobj, g_ens) # Update ensemble\nend","category":"page"},{"location":"unscented_kalman_inversion/#Solution","page":"Unscented Kalman Inversion","title":"Solution","text":"","category":"section"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"The solution of the unscented Kalman inversion algorithm is a Gaussian distribution whose mean and covariance can be extracted from the ''last ensemble'' (i.e., the ensemble after the last iteration). The sample mean of the last ensemble is also the \"optimal\" parameter (θ_optim) for the given calibration problem. These statistics can be accessed as follows: ","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"# mean of the Gaussian distribution, also the optimal parameter for the calibration problem\nθ_optim = ukiobj.process.u_mean[end], \n# covariance of the Gaussian distribution\nsigma = ukiobj.process.uu_cov[end]","category":"page"},{"location":"unscented_kalman_inversion/","page":"Unscented Kalman Inversion","title":"Unscented Kalman Inversion","text":"There are two examples Lorenz96 and Cloudy","category":"page"},{"location":"examples/Cloudy_example/#Cloudy-Example","page":"Cloudy Example","title":"Cloudy Example","text":"","category":"section"},{"location":"examples/Cloudy_example/#Overview","page":"Cloudy Example","title":"Overview","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"This example is based on Cloudy, a microphysics model that simulates how cloud droplets collide and coalesce into larger drops. Collision-coalescence is a crucial process for the formation of rain. ","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"Cloudy is initialized with a mass distribution of the cloud droplets; this distribution is then evolved in time, with more and more droplets colliding and combining into bigger drops according to the droplet-droplet interactions specified by a collision-coalescence kernel. The evolution is completely determined by the shape of the initial distribution and the form of the kernel.","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"This example shows how ensemble Kalman methods can be used to learn the parameters of the initial cloud droplet mass distribution from observations of the moments of that mass distribution at a later time. The collision-coalescence kernel is assumed to be known, but one could also learn the parameters of the kernel instead of the parameters of the droplet distribution (or both).","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"Cloudy is used here in a \"perfect model\" (aka \"known truth\") setting, which means that the \"observations\" are generated by Cloudy itself, by running it with the true parameter values. In more realistic applications, this parameter estimation procedure will use actual measurements of cloud properties to obtain an estimated droplet mass distribution at a previous time.","category":"page"},{"location":"examples/Cloudy_example/#Prerequisites","page":"Cloudy Example","title":"Prerequisites","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"In order to run this example, you need to install Cloudy.jl (the \"#master\" lets you install the current master branch):","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"pkg > add Cloudy#master","category":"page"},{"location":"examples/Cloudy_example/#Structure","page":"Cloudy Example","title":"Structure","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"The file Cloudy_example_eki.jl sets up the inverse problem and solves it using ensemble Kalman inversion, and the file Cloudy_example_uki.jl does the same using unscented Kalman inversion. The file DynamicalModel.jl provides the functionality to run the dynamical model Psi, which in this example is Cloudy.","category":"page"},{"location":"examples/Cloudy_example/#Running-the-Example","page":"Cloudy Example","title":"Running the Example","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"Once Cloudy is installed, the examples can be run from the julia REPL:","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"# Solve inverse problem using ensemble Kalman inversion\ninclude(\"Cloudy_example_eki.jl\")","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"or","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"# Solve inverse problem using unscented Kalman inversion\ninclude(\"Cloudy_example_uki.jl\")","category":"page"},{"location":"examples/Cloudy_example/#What-Does-Cloudy-Do?","page":"Cloudy Example","title":"What Does Cloudy Do?","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"The mathematical starting point of Cloudy is the stochastic collection equation (SCE; sometimes also called Smoluchowski equation after Marian Smoluchowski), which describes the time rate of change of f = f(m t), the mass distribution function of liquid water droplets, due to the process of collision and coalescence. The distribution function f depends on droplet mass m and time t and is defined such that f(m) text dm denotes the number of droplets with masses in the interval m m + dm per unit volume. ","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"The stochastic collection equation is an integro-differential equation that can be written as ","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"    fracpartial f(m t)partial t = frac12 int_m=0^infty f(m t) f(m-m t)  mathcalC(m m-m)textdm - f(m t) int_m=0^infty f(m t)mathcalC(m m) textdm ","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"where mathcalC(m m) is the collision-coalescence kernel, which  encapsulates the physics of droplet-droplet interactions – it describes the rate at which two drops of masses m and m come into contact and coalesce into a drop of mass m + m. The first term on the right-hand side of the SCE describes the rate of increase of the number of drops having a mass m due to collision and coalescence of drops of masses m and m-m (where the factor frac12 avoids double counting), while the second term describes the rate of reduction of drops of mass m due to collision and coalescence of drops having a mass m with other drops. ","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"We can rewrite the SCE in terms of the moments M_k of f, which are the prognostic variables in Cloudy. They are defined by","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"    M_k = int_0^infty m^k f(m t) textdm","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"The time rate of change of the k-th moment of f is obtained by multiplying the SCE by m^k and integrating over the entire range of droplet masses (from m=0 to infty), which yields","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"    fracpartial M_k(t)partial t = frac12int_0^infty left((m+m)^k - m^k - m^kright) mathcalC(m m)f(m t)f(m t)  textdm textdm  (1)","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"In this example, the kernel is set to be constant – mathcalC(m m) = B = textconst – and the cloud droplet mass distribution is assumed to be a textGamma(k_t theta_t) distribution, scaled by a factor N_0t which denotes the droplet number concentration:","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"f(m t) = fracN_0tGamma(k_t)theta_t^k m^k_t-1 exp(-mtheta_t)","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"The parameter vector phi_t= N_0t k_t theta_t changes over time (as indicated by the subscript t), as the shape of the distribution evolves. In fact, there is a priori no reason to assume that the distribution would retain its Gamma shape over time, but this is a common assumption that is made in order to solve the closure problem (without this assumption, one would have to keep track of infinitely many moments of the mass distribution in order to uniquely identify the distribution f at each time step, which is obviously not practicable).","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"For Gamma mass distribution functions, specifying the first three moments (M_0, M_1, and M_2) is sufficient to uniquely determine the parameter vector phi_t, hence Cloudy solves equation (1) for k = 0 1 2. This mapping of the parameters of the initial cloud droplet mass distribution to the (zeroth-, first-, and second-order) moments of the distribution at a specified end time is done by DynamicalModel.jl.","category":"page"},{"location":"examples/Cloudy_example/#Setting-up-the-Inverse-Problem","page":"Cloudy Example","title":"Setting up the Inverse Problem","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"The goal is to learn the distribution  parameters at time t = 0, phi_0 = N_00 k_0 theta_0, from observations y = M_0(t_end) M_1(t_end) M_2(t_end) of the zeroth-, first-, and second-order moments of the distribution at time t_end  0 (where t_end = 1.0 in this example). This is a known truth experiment, in which the true parameters phi_0 texttrue are defined to be:","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"N0_true = 300.0  # number of particles (scaling factor for Gamma distribution)\nθ_true = 1.5597  # scale parameter of Gamma distribution\nk_true = 0.0817  # shape parameter of Gamma distribution","category":"page"},{"location":"examples/Cloudy_example/#Priors","page":"Cloudy Example","title":"Priors","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"All three parameters have to be strictly positive, so we put lower bounds [lbound_N0, lbound_0, lbound_k] on them and use a shifted log transformation, mathcalT(x) = log(x - textlbound), to map the parameter vector phi_0 to the parameter vector theta = mathcalT(N_00) mathcalT(k_0)mathcalT(theta_0) which is normally distributed:","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"mathcalT(N_00)sim mathcalN(45 10)  mathcalT(k_0) sim mathcalN(00 20) mathcalT(theta_0) sim mathcalN(-10 10). ","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"The ensemble Kalman algorithm is then performed in the unconstrained \"theta-space\" (note: don't confuse the parameter vector theta with the theta_t parameter of the Gamma distribution). A more detailed treatment of these kinds of transformations from constrained/physical to unconstrained/computational parameters is found here.","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"In the code, the priors are constructed as follows:","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"par_names = [\"N0\", \"θ\", \"k\"]\n\nc1 = bounded_below(lbound_N0)\nc2 = bounded_below(lbound_θ)\nc3 = bounded_below(lbound_k)\nconstraints = [[c1], [c2], [c3]]\n\n# We choose to use normal distributions to represent the prior distributions of\n# the parameters in the unconstrained space\nd1 = Parameterized(Normal(4.5, 1.0))  #truth is 5.19\nd2 = Parameterized(Normal(0.0, 2.0))  #truth is 0.378\nd3 = Parameterized(Normal(-1.0, 1.0)) #truth is -2.51\ndistributions = [d1, d2, d3]\n\npriors = ParameterDistribution(distributions, constraints, par_names)","category":"page"},{"location":"examples/Cloudy_example/#Observational-Noise","page":"Cloudy Example","title":"Observational Noise","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"Cloudy produces output  y = M_0(t_end) M_1(t_end) M_2(t_end), which is assumed to be related to the parameter vector theta according to:","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"    y = mathcalG(theta) + eta","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"where mathcalG = Psi circ mathcalT^-1 is the forward map, and the observational noise eta is assumed to be drawn from a  3-dimensional  Gaussian  with distribution mathcalN(0 Gamma_y). In a perfect model setting, the observational noise represents the internal model variability. Since Cloudy is a purely deterministic model, there is no straightforward way of coming up with a covariance Gamma_y for this internal noise. We decide to use a diagonal covariance with the following entries (variances):","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"Γy = convert(Array, Diagonal([100.0, 5.0, 30.0]))","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"Artificial observations (\"truth samples\") are then generated by adding random samples from eta to G_t, the forward map evaluated for the true parameters:","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"for i in 1:n_samples\n    y_t[:, i] = G_t .+ rand(MvNormal(μ, Γy))\nend\n\ntruth = Observations.Obs(y_t, Γy, data_names)","category":"page"},{"location":"examples/Cloudy_example/#Solution-and-Output","page":"Cloudy Example","title":"Solution and Output","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"Cloudy_example_eki.jl: The optimal parameter vector determined by the ensemble Kalman inversion is the ensemble mean of the particles after the last iteration, which is printed to standard output. An output directory is created, where two files are stored: parameter_storage_eki.jld2 and data_storage_eki.jld2, which contain all parameters and model output from the ensemble Kalman iterations, respectively (both as DataStorage.DataContainer objects). In addition, an animation is produced that shows the evolution of the ensemble of particles over subsequent iterations of the optimization.\nCloudy_example_uki.jl: In addition to a point estimate of the optimal parameter (which is again given by the ensemble mean of the last iteration and printed to standard output), Unscented Kalman inversion also provides a covariance approximation of the posterior distribution. Together, the mean and covariance allow for the reconstruction of a Gaussian approximation of the posterior distribution. The evolution of this Gaussian approximation over subsequent iterations is shown as an animation. All parameters as well as the model output from the unscented Kalman inversion are stored in an output directory, as parameter_storage_uki.jld2 and data_storage_uki.jld2.","category":"page"},{"location":"examples/Cloudy_example/#Playing-Around","page":"Cloudy Example","title":"Playing Around","text":"","category":"section"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"If you want to play around with the Cloudy examples, you can e.g. change the type or the parameters of the initial cloud droplet mass distribution (see Cloudy.ParticleDistributions for the available distributions), by modifying these lines:","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"ϕ_true = [N0_true, θ_true, k_true]\ndist_true = ParticleDistributions.GammaPrimitiveParticleDistribution(ϕ_true...)","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"(Don't forget to also change dist_type accordingly).","category":"page"},{"location":"examples/Cloudy_example/","page":"Cloudy Example","title":"Cloudy Example","text":"You can also experiment with different noise covariances (Γy), priors, vary the number of iterations (N_iter) or ensemble particles (N_ens), etc.","category":"page"},{"location":"#EnsembleKalmanProcesses","page":"Home","title":"EnsembleKalmanProcesses","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"EnsembleKalmanProcesses.jl (EKP) is a library of derivative-free Bayesian optimization techniques based on the Ensemble Kalman Filters, a well known family of approximate filters used for data assimilation. Currently, the following methods are implemented in the library:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Ensemble Kalman Inversion (EKI) - The traditional optimization technique based on the Ensemble Kalman Filter EnKF (Iglesias, Law, Stuart 2013),\nEnsemble Kalman Sampler (EKS) - also obtains a Gaussian Approximation of the posterior distribution, through a Monte Carlo integration (Garbuno-Inigo, Hoffmann, Li, Stuart 2020),\nUnscented Kalman Inversion (UKI) - also obtains a Gaussian Approximation of the posterior distribution, through a quadrature based integration approach (Huang Schneider Stuart 2020),\n[coming soon] Sparsity preserving Ensemble Kalman Inversion (SEKI) - Additionally adds approximate L^0 and L^1 penalization to the EKI (Schneider, Stuart, Wu 2020).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Module Purpose\nEnsembleKalmanProcesses.jl Collection of all tools\nEnsembleKalmanProcess.jl Implementations of EKI, EKS and UKI\nObservations.jl Structure to hold observational data\nParameterDistributions.jl Structures to hold prior and posterior distributions\nDataStorage.jl Structure to hold model parameters and outputs","category":"page"},{"location":"API/DataStorage/#DataStorage","page":"DataStorage","title":"DataStorage","text":"","category":"section"},{"location":"API/DataStorage/","page":"DataStorage","title":"DataStorage","text":"CurrentModule = EnsembleKalmanProcesses.DataStorage","category":"page"},{"location":"API/DataStorage/","page":"DataStorage","title":"DataStorage","text":"DataContainer\nPairedDataContainer\nsize","category":"page"},{"location":"API/DataStorage/#EnsembleKalmanProcesses.DataStorage.DataContainer","page":"DataStorage","title":"EnsembleKalmanProcesses.DataStorage.DataContainer","text":"struct DataContainer{FT <: Real}\n\nstruct to store data samples as columns in an array\n\n\n\n\n\n","category":"type"},{"location":"API/DataStorage/#EnsembleKalmanProcesses.DataStorage.PairedDataContainer","page":"DataStorage","title":"EnsembleKalmanProcesses.DataStorage.PairedDataContainer","text":"PairedDataContainer{FT <: Real}\n\nstores input - output pairs as data containers, there must be an equal number of inputs and outputs\n\n\n\n\n\n","category":"type"},{"location":"API/DataStorage/#Base.size","page":"DataStorage","title":"Base.size","text":"size(dc::DataContainer,idx::IT) where {IT <: Integer}\n\nreturns the size of the stored data (if idx provided, it returns the size along dimension idx) \n\n\n\n\n\nsize(pdc::PairedDataContainer,idx::IT) where {IT <: Integer}\n\nreturns the sizes of the inputs and ouputs along dimension idx (if provided)\n\n\n\n\n\n","category":"function"}]
}
